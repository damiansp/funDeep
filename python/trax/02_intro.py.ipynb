{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derived from the docs' tutorial <a href=\"https://trax-ml.readthedocs.io/en/latest/notebooks/trax_intro.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# Copyright 2020 Google LLC.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trax\n",
    "from   trax import layers as tl\n",
    "from   trax.fastmath import numpy as fastnp\n",
    "from   trax.supervised import training\n",
    "\n",
    "trax.fastmath.use_backend('jax'); # or 'tensorflow-numpy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Vector: [1. 1. 1.]\n",
      "Dot product: [12. 15. 18.]\n",
      "tanh(prod): [1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "M = fastnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f'Matrix:\\n{M}')\n",
    "\n",
    "v = fastnp.ones(3)\n",
    "print(f'Vector: {v}')\n",
    "\n",
    "dot_prod = fastnp.dot(v, M)\n",
    "print(f'Dot product: {dot_prod}')\n",
    "\n",
    "tanh = fastnp.tanh(dot_prod)\n",
    "print(f'tanh(prod): {tanh}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2. * x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad(2x^2) at 1: 4.0\n",
      "grad(2x^2) at -2: -8.0\n"
     ]
    }
   ],
   "source": [
    "grad_f = trax.fastmath.grad(f)\n",
    "\n",
    "print(f'grad(2x^2) at 1: {grad_f(1.)}')\n",
    "print(f'grad(2x^2) at -2: {grad_f(-2.)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "y.shape: (15, 32)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(15)\n",
    "print(f'x: {x}')\n",
    "      \n",
    "# Create embedding layer\n",
    "embedding = tl.Embedding(vocab_size=20, d_feature=32)\n",
    "embedding.init(trax.shapes.signature(x))\n",
    "\n",
    "# Run the layer -- y = embedding(x)\n",
    "y = embedding(x)\n",
    "print(f'y.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  Embedding_8192_256\n",
       "  Mean\n",
       "  Dense_2\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = tl.Serial(tl.Embedding(vocab_size=8192, d_feature=256),\n",
    "                tl.Mean(axis=1), # mean sent length\n",
    "                tl.Dense(2),     # classify 2 classes\n",
    "                tl.LogSoftmax()) # log probs\n",
    "mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stream = trax.data.TFDS(\n",
    "    'imdb_reviews', keys=('text', 'label'), train=True\n",
    ")()\n",
    "eval_stream = trax.data.TFDS(\n",
    "    'imdb_reviews', keys=('text', 'label'), train=False\n",
    ")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.', 0)\n"
     ]
    }
   ],
   "source": [
    "print(next(train_stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(\n",
    "    trax.data.Tokenize(vocab_file='en_8k.subword', keys=[0]),\n",
    "    trax.data.Shuffle(),\n",
    "    trax.data.FilterByLength(max_length=2048, length_keys=[0]),\n",
    "    trax.data.BucketByLength(boundaries=[32, 128, 512, 2048], \n",
    "                             batch_sizes=[512, 128, 32, 8, 1], \n",
    "                             length_keys=[0]),\n",
    "    trax.data.AddLossWeights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes = [(8, 2048), (8,), (8,)]\n"
     ]
    }
   ],
   "source": [
    "train_batches_stream = data_pipeline(train_stream)\n",
    "eval_batches_stream = data_pipeline(eval_stream)\n",
    "example_batch = next(train_batches_stream)\n",
    "print(f'shapes = {[x.shape for x in example_batch]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Ran 1 train steps in 0.96 secs\n",
      "Step      1: train CrossEntropyLoss |  0.69560391\n",
      "Step      1: eval  CrossEntropyLoss |  0.70317779\n",
      "Step      1: eval          Accuracy |  0.47343750\n",
      "\n",
      "Step    500: Ran 499 train steps in 14.22 secs\n",
      "Step    500: train CrossEntropyLoss |  0.51409441\n",
      "Step    500: eval  CrossEntropyLoss |  0.53382829\n",
      "Step    500: eval          Accuracy |  0.77968750\n"
     ]
    }
   ],
   "source": [
    "train_task = training.TrainTask(labeled_data=train_batches_stream,\n",
    "                                loss_layer=tl.CrossEntropyLoss(),\n",
    "                                optimizer=trax.optimizers.Adam(0.01),\n",
    "                                n_steps_per_checkpoint=500)\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=eval_batches_stream,\n",
    "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    "    n_eval_batches=20)\n",
    "\n",
    "output_dir = './output'\n",
    "!rm -rf $output_dir\n",
    "\n",
    "training_loop = training.Loop(\n",
    "    mod, train_task, eval_tasks=[eval_task], output_dir=output_dir)\n",
    "training_loop.run(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: **Warning! Slight Plot Spoilers Ahead!**<br /><br />\"The Italian Job\" is not the best movie you'll see all year, or probably even this summer. But it is a worthwhile two hours because it colors within the lines, knowing its limits and not attempting to exceed them.<br /><br />What carries the movie is the work of the cast. In a movie about a crew of thieves, the individuals must have a good rapport with each other. Without that cohesive feel, the audience doesn't believe in the characters collectively or individually, and the movie never has a chance. But from the first scenes, in which the men joke around and rag on each other while infiltrating a Venetian palace, the proper chemistry is in place.<br /><br />The characters themselves aren't anything novel; they're your basic gang of criminals, containing about half a dozen players, each with a specific and defining skill. But each actor brings the proper goods to the table for his or her part. Mark Wahlberg's understated acting and humor fits well with his part as the mastermind planner. Edward Norton provides attitude and twirls his mustache well in his dark role. Donald Sutherland is the father figure of the crew, and he looks the part of the suave and old-fashioned thief, who is still mentally spry. Jason Statham, Seth Green, and Mos Def don't do much beyond their character's abilities, but they each nail those parts. Statham as the smooth-operating driver; Green as the tech whiz geek with a chip on his shoulder; and Def as the demolitions man. Charlize Theron slides in well in a part that doesn't ask too much of her. She is primarily asked to to drive fast and look good. That she does. None of the characters are that deep or three-dimensional, but in this familiar sort of movie, two dimensions are all that is required. <br /><br />As the title implies, the movie has a European feel to it, a la \"The Bourne Identity,\" in part because it was shot on location in Venice, along with Philadelphia and Los Angeles. Also contributing to the Euro flair is the rhythmic, bouncy music, which adds to the upbeat nature of the flick and complements the rapport of the cast. The look of the movie is also a perfect match. The bright colors of all locales enhance the mood and add to the attitude. The Minis not only provide a fun variation on the car chase, but also work as a necessary plot device. <br /><br />The plot is more or less straight-forward. There are a few surprises, but they are more of the swift-and-smooth-turn variety, as opposed to the drop-your-jaw hairpin curve. Even with those, the movie speeds along. Once the foundation is laid by the first act, everything continuously progresses. Thankfully there are no breaks in the action for a romance, something the movie wisely avoided. There aren't even any breaks for 'real life.' The story has its purpose and runs that course without distractions. The lack of character depth prevents \"The Italian Job\" from being more than a good popcorn movie, but with all the complex details of the heist-planning, such superfluities would have dragged down the pace and quality of the flick.<br /><br />There are a number of implausibilities that I thought of both during and after viewing. But the movie is so enjoyable that I didn't and don't care. In the real world, most of the movie probably couldn't have gone off that cleanly. But \"The Italian Job\" doesn't take place in the real world. It occurs in a stylish and light-hearted criminal world that appeals to the rebel in all of us. <br /><br />\"The Italian Job\" is a movie, in the true sense of the word. It has no pretenses of Oscar and contains no deep moral message. It provides pure escapism entertainment and does so quite well.<br /><br />Bottom Line: Maybe the best popcorn movie of the year so far. 7 of 10.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Sentiment probs: [[0.02387173 0.9761283 ]]\n"
     ]
    }
   ],
   "source": [
    "example_input = next(eval_batches_stream)[0][0]\n",
    "example_input_str = trax.data.detokenize(example_input, \n",
    "                                         vocab_file='en_8k.subword')\n",
    "print(f'Input: {example_input_str}')\n",
    "sentiment_log_probs = mod(example_input[None, :])\n",
    "print(f'Sentiment probs: {np.exp(sentiment_log_probs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
