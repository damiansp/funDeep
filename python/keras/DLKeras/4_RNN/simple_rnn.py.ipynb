{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALICE_PATH = '/Users/dsp/nltk_data/corpora/gutenberg/carroll-alice.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(ALICE_PATH) as f:\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        line = line.strip().lower()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "    text = ' '.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[alice's adventures in wonderland by lewis carroll\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "chars = set([c for c in text])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)\n",
    "\n",
    "char2index = {c: i for i, c in enumerate(chars)} \n",
    "# 'a': 40, 'b': 18, 'c': 10...\n",
    "\n",
    "index2char = {i: c for i, c in enumerate(chars)} \n",
    "# 0: ')', 1: 'u', 2: 'r'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 10\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQ_LEN, STEP) :\n",
    "    input_chars.append(text[i:i + SEQ_LEN])\n",
    "    label_chars.append(text[i + SEQ_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alice's a -> d\n",
      "alice's ad -> v\n",
      "lice's adv -> e\n"
     ]
    }
   ],
   "source": [
    "print(f'{input_chars[0]} -> {label_chars[0]}')\n",
    "print(f'{input_chars[1]} -> {label_chars[1]}')\n",
    "print(f'{input_chars[2]} -> {label_chars[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in X is:\n",
    "SEQ_LEN = 10 x n_chars = 46 letters + punctuation, etc.\n",
    " = 460 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.zeros([len(input_chars), SEQ_LEN, n_chars], dtype=np.bool)\n",
    "y = np.zeros([len(input_chars), n_chars], dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH = 128\n",
    "ITER = 25\n",
    "EPOCHS = 1\n",
    "PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, \n",
    "                    return_sequences=False, \n",
    "                    input_shape=[SEQ_LEN, n_chars],\n",
    "                    unroll=True))\n",
    "model.add(Dense(n_chars))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 196us/step - loss: 2.2979\n",
      "Generating from seed: iculty was\n",
      "iculty wast and and alice aad the the wast on and and alice aad the the wast on and and alice aad the the wast\n",
      "==================================================\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 25s 177us/step - loss: 2.0384\n",
      "Generating from seed: half my pl\n",
      "half my plong the hand and then the hat she hand and then the hat she hand and then the hat she hand and then \n",
      "==================================================\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 25s 173us/step - loss: 1.9516\n",
      "Generating from seed:  she remar\n",
      " she remars all the the hat sal cous and all the the hat sal cous and all the the hat sal cous and all the the\n",
      "==================================================\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 25s 173us/step - loss: 1.8632\n",
      "Generating from seed:  the hatte\n",
      " the hatter she was and theard thear sheard thear sheard thear sheard thear sheard thear sheard thear sheard t\n",
      "==================================================\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 179us/step - loss: 1.7777\n",
      "Generating from seed: iness?' th\n",
      "iness?' the she she said to she she said to she she said to she she said to she she said to she she said to sh\n",
      "==================================================\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 180us/step - loss: 1.7034\n",
      "Generating from seed: head over \n",
      "head over hel she wald the gryphon, who sald the malt be which laster sout to the dolles in the dild an the do\n",
      "==================================================\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 179us/step - loss: 1.6389\n",
      "Generating from seed: ng their e\n",
      "ng their eacher dinner while the right she was no reand the dont of the round alice she was no reand the dont \n",
      "==================================================\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 182us/step - loss: 1.5849\n",
      "Generating from seed:  the cakes\n",
      " the cakes, and the done was good of the look of the lat or the lat or the lat or the lat or the lat or the la\n",
      "==================================================\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 182us/step - loss: 1.5383\n",
      "Generating from seed: hese words\n",
      "hese words a thing the ere. 'i was so much as the rea. 'whe wan the rea. 'whe wan the rea. 'whe wan the rea. '\n",
      "==================================================\n",
      "Iteration 10\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 180us/step - loss: 1.4965\n",
      "Generating from seed: nearer to \n",
      "nearer to the some the surped on the out of the sout of the sout of the sout of the sout of the sout of the so\n",
      "==================================================\n",
      "Iteration 11\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 185us/step - loss: 1.4592\n",
      "Generating from seed:  chapter i\n",
      " chapter in a morent was the white rabbit was the white rabbit was the white rabbit was the white rabbit was t\n",
      "==================================================\n",
      "Iteration 12\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 184us/step - loss: 1.4269\n",
      "Generating from seed: f talking \n",
      "f talking at the first off the sare silence the dormouse soon the dormouse soon the dormouse soon the dormouse\n",
      "==================================================\n",
      "Iteration 13\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 25s 175us/step - loss: 1.3985\n",
      "Generating from seed: f neck, wh\n",
      "f neck, who would bean it was not mame of the tone of the tone of the tone of the tone of the tone of the tone\n",
      "==================================================\n",
      "Iteration 14\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 179us/step - loss: 1.3738\n",
      "Generating from seed: l else for\n",
      "l else for the large tood a as she was a little parss of the some of the some of the some of the some of the s\n",
      "==================================================\n",
      "Iteration 15\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 25s 179us/step - loss: 1.3486\n",
      "Generating from seed:  and sneez\n",
      " and sneeze do the that was a little began well as she could not shaller latter off a this tome that down and \n",
      "==================================================\n",
      "Iteration 16\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 198us/step - loss: 1.3266\n",
      "Generating from seed: l too flus\n",
      "l too flust the march hare said to herself, 'i wonder which asked a with the laiden, and expeaning in a tone i\n",
      "==================================================\n",
      "Iteration 17\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 27s 191us/step - loss: 1.3068\n",
      "Generating from seed: t to her, \n",
      "t to her, and the shall the king and lask to her eled the poor little shorien the latter was not mare the gryp\n",
      "==================================================\n",
      "Iteration 18\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 196us/step - loss: 1.2889\n",
      "Generating from seed: id the kin\n",
      "id the king, 'and it was all the tried to the dormouse is all the tried to the dormouse is all the tried to th\n",
      "==================================================\n",
      "Iteration 19\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 196us/step - loss: 1.2730\n",
      "Generating from seed: ite forgot\n",
      "ite forgot and for a caterpout of the words: 'i don't like the same that i can her once some more sor so she c\n",
      "==================================================\n",
      "Iteration 20\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 26s 180us/step - loss: 1.2582\n",
      "Generating from seed: bout this \n",
      "bout this the out of the hatter: 'the hatter: 'the hatter: 'the hatter: 'the hatter: 'the hatter: 'the hatter:\n",
      "==================================================\n",
      "Iteration 21\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 29s 203us/step - loss: 1.2423\n",
      "Generating from seed:  said the \n",
      " said the duchess, 'wh cearing about it a canding the suches lying of the sare. 'i dear!' cried the mock turtl\n",
      "==================================================\n",
      "Iteration 22\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 198us/step - loss: 1.2278\n",
      "Generating from seed: ne in by m\n",
      "ne in by marked the reaches and a little shrilk about in all did canch in a very solking at the cat was soill \n",
      "==================================================\n",
      "Iteration 23\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 199us/step - loss: 1.2153\n",
      "Generating from seed: rt of way,\n",
      "rt of way, 'a the same so they were now it would be a little said a very supplessed of followed his face, and \n",
      "==================================================\n",
      "Iteration 24\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 29s 203us/step - loss: 1.2024\n",
      "Generating from seed:  they pinc\n",
      " they pincem, and was out of the will the white rabbit was no thing i thought it was out of the will the white\n",
      "==================================================\n",
      "Iteration 25\n",
      "Epoch 1/1\n",
      "142594/142594 [==============================] - 28s 199us/step - loss: 1.1924\n",
      "Generating from seed: allow me t\n",
      "allow me to do the mouse to the mouse to the mouse to the mouse to the mouse to the mouse to the mouse to the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(ITER):\n",
    "    print('=' * 50)\n",
    "    print(f'Iteration {i + 1}')\n",
    "    model.fit(X, y, batch_size=BATCH, epochs=EPOCHS)\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(f'Generating from seed: {test_chars}')\n",
    "    print(test_chars, end='')\n",
    "    for i in range(PREDS_PER_EPOCH):\n",
    "        X_test = np.zeros((1, SEQ_LEN, n_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            X_test[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "        print(y_pred, end='')\n",
    "        test_chars = test_chars[1:] + y_pred # shift\n",
    "    print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
