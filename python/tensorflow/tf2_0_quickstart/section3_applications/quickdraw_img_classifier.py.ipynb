{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from   sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D)\n",
    "from   tensorflow.keras.losses import categorical_crossentropy as cxe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_numpy_bitmap_ambulance.npy   full_numpy_bitmap_mermaid.npy\r\n",
      "full_numpy_bitmap_crocodile.npy   full_numpy_bitmap_raccoon.npy\r\n",
      "full_numpy_bitmap_eye.npy         full_numpy_bitmap_rifle.npy\r\n",
      "full_numpy_bitmap_flamingo.npy    full_numpy_bitmap_snail.npy\r\n",
      "full_numpy_bitmap_harp.npy        full_numpy_bitmap_stethoscope.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../data/quickdraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../../../../data/quickdraw'\n",
    "FILE_TEMPLATE = f'{DATA}/full_numpy_bitmap_%s.npy'\n",
    "categories = ['ambulance', 'crocodile', 'eye', 'flamingo', 'harp', \n",
    "              'mermaid', 'raccoon', 'rifle', 'snail', 'stethoscope']\n",
    "filenames = [FILE_TEMPLATE % x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH = 128\n",
    "DIM = 28\n",
    "N_IMAGES = 100000 # reduce if mem issues\n",
    "N_FILES = len(categories)\n",
    "IMAGES_PER_CATEGORY = N_IMAGES // N_FILES\n",
    "IMAGES_PER_CATEGORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for path in filenames:\n",
    "    x = np.load(path)\n",
    "    x = x.astype('float32') / 255.\n",
    "    y = [i] * len(x)\n",
    "    x = x[:IMAGES_PER_CATEGORY]\n",
    "    y = y[:IMAGES_PER_CATEGORY]\n",
    "    if i == 0:\n",
    "        x_all = x\n",
    "        y_all = y\n",
    "    else:\n",
    "        x_all = np.concatenate((x, x_all), axis=0)\n",
    "        y_all = np.concatenate((y, y_all), axis=0)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, test_size=0.2, random_state=1103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], DIM, DIM, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], DIM, DIM, 1)\n",
    "input_shape = (DIM, DIM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, N_FILES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, N_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=1103)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Sequential()\n",
    "\n",
    "mod.add(Conv2D(\n",
    "    32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "mod.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "mod.add(Dropout(DROP))\n",
    "\n",
    "mod.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "mod.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "mod.add(Dropout(DROP))\n",
    "\n",
    "mod.add(Flatten())\n",
    "mod.add(Dense(128, activation='relu'))\n",
    "mod.add(Dropout(2 * DROP))\n",
    "mod.add(Dense(N_FILES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(loss=cxe, \n",
    "            optimizer=tf.keras.optimizers.Adadelta(), \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./tb_log_dir')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/25\n",
      "72000/72000 [==============================] - 46s 643us/sample - loss: 2.2983 - accuracy: 0.1184 - val_loss: 2.2594 - val_accuracy: 0.1835\n",
      "Epoch 2/25\n",
      "72000/72000 [==============================] - 48s 661us/sample - loss: 2.2565 - accuracy: 0.1448 - val_loss: 2.2240 - val_accuracy: 0.2421\n",
      "Epoch 3/25\n",
      "72000/72000 [==============================] - 47s 654us/sample - loss: 2.2179 - accuracy: 0.1809 - val_loss: 2.1849 - val_accuracy: 0.3040\n",
      "Epoch 4/25\n",
      "72000/72000 [==============================] - 48s 668us/sample - loss: 2.1767 - accuracy: 0.2086 - val_loss: 2.1397 - val_accuracy: 0.3400\n",
      "Epoch 5/25\n",
      "72000/72000 [==============================] - 48s 664us/sample - loss: 2.1350 - accuracy: 0.2345 - val_loss: 2.0904 - val_accuracy: 0.3776\n",
      "Epoch 6/25\n",
      "72000/72000 [==============================] - 48s 661us/sample - loss: 2.0911 - accuracy: 0.2574 - val_loss: 2.0374 - val_accuracy: 0.4105\n",
      "Epoch 7/25\n",
      "72000/72000 [==============================] - 47s 659us/sample - loss: 2.0450 - accuracy: 0.2754 - val_loss: 1.9822 - val_accuracy: 0.4296\n",
      "Epoch 8/25\n",
      "72000/72000 [==============================] - 48s 660us/sample - loss: 2.0001 - accuracy: 0.2916 - val_loss: 1.9274 - val_accuracy: 0.4538\n",
      "Epoch 9/25\n",
      "72000/72000 [==============================] - 48s 660us/sample - loss: 1.9586 - accuracy: 0.3053 - val_loss: 1.8748 - val_accuracy: 0.4629\n",
      "Epoch 10/25\n",
      "72000/72000 [==============================] - 50s 691us/sample - loss: 1.9208 - accuracy: 0.3199 - val_loss: 1.8260 - val_accuracy: 0.4760\n",
      "Epoch 11/25\n",
      "72000/72000 [==============================] - 49s 678us/sample - loss: 1.8847 - accuracy: 0.3327 - val_loss: 1.7810 - val_accuracy: 0.4812\n",
      "Epoch 12/25\n",
      "72000/72000 [==============================] - 49s 675us/sample - loss: 1.8557 - accuracy: 0.3409 - val_loss: 1.7417 - val_accuracy: 0.4875\n",
      "Epoch 13/25\n",
      "72000/72000 [==============================] - 49s 676us/sample - loss: 1.8282 - accuracy: 0.3518 - val_loss: 1.7069 - val_accuracy: 0.4933\n",
      "Epoch 14/25\n",
      "72000/72000 [==============================] - 48s 661us/sample - loss: 1.8061 - accuracy: 0.3581 - val_loss: 1.6757 - val_accuracy: 0.5011\n",
      "Epoch 15/25\n",
      "72000/72000 [==============================] - 48s 672us/sample - loss: 1.7829 - accuracy: 0.3689 - val_loss: 1.6474 - val_accuracy: 0.5044\n",
      "Epoch 16/25\n",
      "72000/72000 [==============================] - 48s 661us/sample - loss: 1.7600 - accuracy: 0.3779 - val_loss: 1.6218 - val_accuracy: 0.5107\n",
      "Epoch 17/25\n",
      "72000/72000 [==============================] - 48s 661us/sample - loss: 1.7375 - accuracy: 0.3900 - val_loss: 1.5981 - val_accuracy: 0.5140\n",
      "Epoch 18/25\n",
      "72000/72000 [==============================] - 48s 660us/sample - loss: 1.7223 - accuracy: 0.3956 - val_loss: 1.5769 - val_accuracy: 0.5191\n",
      "Epoch 19/25\n",
      "72000/72000 [==============================] - 48s 664us/sample - loss: 1.7011 - accuracy: 0.4033 - val_loss: 1.5565 - val_accuracy: 0.5254\n",
      "Epoch 20/25\n",
      "72000/72000 [==============================] - 48s 665us/sample - loss: 1.6855 - accuracy: 0.4108 - val_loss: 1.5375 - val_accuracy: 0.5280\n",
      "Epoch 21/25\n",
      "72000/72000 [==============================] - 48s 668us/sample - loss: 1.6728 - accuracy: 0.4164 - val_loss: 1.5199 - val_accuracy: 0.5355\n",
      "Epoch 22/25\n",
      "72000/72000 [==============================] - 47s 657us/sample - loss: 1.6563 - accuracy: 0.4242 - val_loss: 1.5034 - val_accuracy: 0.5404\n",
      "Epoch 23/25\n",
      "72000/72000 [==============================] - 47s 653us/sample - loss: 1.6398 - accuracy: 0.4299 - val_loss: 1.4873 - val_accuracy: 0.5445\n",
      "Epoch 24/25\n",
      "72000/72000 [==============================] - 47s 654us/sample - loss: 1.6255 - accuracy: 0.4352 - val_loss: 1.4714 - val_accuracy: 0.5506\n",
      "Epoch 25/25\n",
      "72000/72000 [==============================] - 48s 663us/sample - loss: 1.6137 - accuracy: 0.4423 - val_loss: 1.4568 - val_accuracy: 0.5545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a507a2650>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train, \n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4618729888916016\n",
      "Test Acc: 0.5468999743461609\n"
     ]
    }
   ],
   "source": [
    "score = mod.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}\\nTest Acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ambulance', 'crocodile', 'eye', 'flamingo', 'harp', 'mermaid', 'raccoon', 'rifle', 'snail', 'stethoscope']\n",
      "Predicted       Actual\n",
      "----------------------\n",
      "snail           snail\n",
      "eye             snail\n",
      "crocodile       crocodile\n",
      "raccoon         harp\n",
      "ambulance       ambulance\n",
      "rifle           rifle\n",
      "eye             eye\n",
      "harp            eye\n",
      "ambulance       ambulance\n",
      "snail           eye\n",
      "raccoon         stethoscope\n",
      "flamingo        stethoscope\n",
      "rifle           rifle\n",
      "flamingo        flamingo\n",
      "eye             eye\n",
      "snail           mermaid\n",
      "rifle           rifle\n",
      "harp            harp\n",
      "harp            stethoscope\n",
      "ambulance       mermaid\n"
     ]
    }
   ],
   "source": [
    "print(categories)\n",
    "print('Predicted       Actual')\n",
    "print('----------------------')\n",
    "\n",
    "for _ in range(20):\n",
    "    t = np.random.randint(len(X_test))\n",
    "    x1 = X_test[t].reshape(1, DIM, DIM, 1)\n",
    "    p = mod.predict(x1)\n",
    "    print(f'{categories[np.argmax(p)]:15s} '\n",
    "          f'{categories[np.argmax(y_test[t])]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=./tb_log_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
