{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "from   sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D)\n",
    "from   tensorflow.keras.losses import categorical_crossentropy as cxe\n",
    "from   tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_numpy_bitmap_ambulance.npy   full_numpy_bitmap_mermaid.npy\r\n",
      "full_numpy_bitmap_crocodile.npy   full_numpy_bitmap_raccoon.npy\r\n",
      "full_numpy_bitmap_eye.npy         full_numpy_bitmap_rifle.npy\r\n",
      "full_numpy_bitmap_flamingo.npy    full_numpy_bitmap_snail.npy\r\n",
      "full_numpy_bitmap_harp.npy        full_numpy_bitmap_stethoscope.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../data/quickdraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../../../../data/quickdraw'\n",
    "FILE_TEMPLATE = f'{DATA}/full_numpy_bitmap_%s.npy'\n",
    "categories = ['ambulance', 'crocodile', 'eye', 'flamingo', 'harp', \n",
    "              'mermaid', 'raccoon', 'rifle', 'snail', 'stethoscope']\n",
    "filenames = [FILE_TEMPLATE % x for x in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH = 128\n",
    "DIM = 28\n",
    "N_IMAGES = 100000 # reduce if mem issues\n",
    "N_FILES = len(categories)\n",
    "IMAGES_PER_CATEGORY = N_IMAGES // N_FILES\n",
    "IMAGES_PER_CATEGORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for path in filenames:\n",
    "    x = np.load(path)\n",
    "    x = x.astype('float32') / 255.\n",
    "    y = [i] * len(x)\n",
    "    x = x[:IMAGES_PER_CATEGORY]\n",
    "    y = y[:IMAGES_PER_CATEGORY]\n",
    "    if i == 0:\n",
    "        x_all = x\n",
    "        y_all = y\n",
    "    else:\n",
    "        x_all = np.concatenate((x, x_all), axis=0)\n",
    "        y_all = np.concatenate((y, y_all), axis=0)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, test_size=0.2, random_state=1103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], DIM, DIM, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], DIM, DIM, 1)\n",
    "input_shape = (DIM, DIM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, N_FILES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, N_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=1103)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Sequential()\n",
    "\n",
    "mod.add(Conv2D(\n",
    "    32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "mod.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "mod.add(Dropout(DROP))\n",
    "\n",
    "mod.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "mod.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "mod.add(Dropout(DROP))\n",
    "\n",
    "mod.add(Flatten())\n",
    "mod.add(Dense(128, activation='relu'))\n",
    "mod.add(Dropout(2 * DROP))\n",
    "mod.add(Dense(N_FILES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(loss=cxe, \n",
    "            optimizer=tf.keras.optimizers.Adadelta(), \n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./tb_log_dir')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 8000 samples\n",
      "Epoch 1/25\n",
      "72000/72000 [==============================] - 48s 670us/sample - loss: 2.3040 - accuracy: 0.1094 - val_loss: 2.2741 - val_accuracy: 0.1474\n",
      "Epoch 2/25\n",
      "72000/72000 [==============================] - 48s 661us/sample - loss: 2.2649 - accuracy: 0.1418 - val_loss: 2.2398 - val_accuracy: 0.2105\n",
      "Epoch 3/25\n",
      "72000/72000 [==============================] - 50s 695us/sample - loss: 2.2299 - accuracy: 0.1703 - val_loss: 2.2013 - val_accuracy: 0.2964\n",
      "Epoch 4/25\n",
      "72000/72000 [==============================] - 49s 682us/sample - loss: 2.1898 - accuracy: 0.2050 - val_loss: 2.1551 - val_accuracy: 0.3531\n",
      "Epoch 5/25\n",
      "72000/72000 [==============================] - 49s 677us/sample - loss: 2.1437 - accuracy: 0.2380 - val_loss: 2.0994 - val_accuracy: 0.3832\n",
      "Epoch 6/25\n",
      "72000/72000 [==============================] - 49s 676us/sample - loss: 2.0941 - accuracy: 0.2603 - val_loss: 2.0365 - val_accuracy: 0.4106\n",
      "Epoch 7/25\n",
      "72000/72000 [==============================] - 49s 675us/sample - loss: 2.0396 - accuracy: 0.2838 - val_loss: 1.9706 - val_accuracy: 0.4310\n",
      "Epoch 8/25\n",
      "72000/72000 [==============================] - 48s 669us/sample - loss: 1.9861 - accuracy: 0.2995 - val_loss: 1.9060 - val_accuracy: 0.4482\n",
      "Epoch 9/25\n",
      "72000/72000 [==============================] - 49s 674us/sample - loss: 1.9401 - accuracy: 0.3129 - val_loss: 1.8463 - val_accuracy: 0.4674\n",
      "Epoch 10/25\n",
      "72000/72000 [==============================] - 48s 667us/sample - loss: 1.8954 - accuracy: 0.3292 - val_loss: 1.7924 - val_accuracy: 0.4859\n",
      "Epoch 11/25\n",
      "72000/72000 [==============================] - 49s 676us/sample - loss: 1.8595 - accuracy: 0.3374 - val_loss: 1.7451 - val_accuracy: 0.4969\n",
      "Epoch 12/25\n",
      "72000/72000 [==============================] - 49s 685us/sample - loss: 1.8252 - accuracy: 0.3499 - val_loss: 1.7038 - val_accuracy: 0.5026\n",
      "Epoch 13/25\n",
      "72000/72000 [==============================] - 48s 666us/sample - loss: 1.7971 - accuracy: 0.3605 - val_loss: 1.6676 - val_accuracy: 0.5123\n",
      "Epoch 14/25\n",
      "72000/72000 [==============================] - 48s 665us/sample - loss: 1.7701 - accuracy: 0.3701 - val_loss: 1.6350 - val_accuracy: 0.5190\n",
      "Epoch 15/25\n",
      "72000/72000 [==============================] - 48s 662us/sample - loss: 1.7478 - accuracy: 0.3800 - val_loss: 1.6070 - val_accuracy: 0.5274\n",
      "Epoch 16/25\n",
      "72000/72000 [==============================] - 47s 660us/sample - loss: 1.7234 - accuracy: 0.3923 - val_loss: 1.5803 - val_accuracy: 0.5344\n",
      "Epoch 17/25\n",
      "72000/72000 [==============================] - 48s 663us/sample - loss: 1.7039 - accuracy: 0.4008 - val_loss: 1.5558 - val_accuracy: 0.5430\n",
      "Epoch 18/25\n",
      "72000/72000 [==============================] - 48s 663us/sample - loss: 1.6816 - accuracy: 0.4116 - val_loss: 1.5324 - val_accuracy: 0.5491\n",
      "Epoch 19/25\n",
      "72000/72000 [==============================] - 49s 686us/sample - loss: 1.6662 - accuracy: 0.4161 - val_loss: 1.5114 - val_accuracy: 0.5540\n",
      "Epoch 20/25\n",
      "72000/72000 [==============================] - 50s 694us/sample - loss: 1.6470 - accuracy: 0.4269 - val_loss: 1.4910 - val_accuracy: 0.5589\n",
      "Epoch 21/25\n",
      "72000/72000 [==============================] - 49s 678us/sample - loss: 1.6311 - accuracy: 0.4320 - val_loss: 1.4721 - val_accuracy: 0.5669\n",
      "Epoch 22/25\n",
      "72000/72000 [==============================] - 49s 682us/sample - loss: 1.6089 - accuracy: 0.4438 - val_loss: 1.4531 - val_accuracy: 0.5702\n",
      "Epoch 23/25\n",
      "72000/72000 [==============================] - 50s 689us/sample - loss: 1.5945 - accuracy: 0.4496 - val_loss: 1.4351 - val_accuracy: 0.5764\n",
      "Epoch 24/25\n",
      "72000/72000 [==============================] - 49s 675us/sample - loss: 1.5819 - accuracy: 0.4570 - val_loss: 1.4180 - val_accuracy: 0.5822\n",
      "Epoch 25/25\n",
      "72000/72000 [==============================] - 48s 665us/sample - loss: 1.5617 - accuracy: 0.4644 - val_loss: 1.4003 - val_accuracy: 0.5863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4d62bb90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train, \n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "        validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4075708951950072\n",
      "Test Acc: 0.5745000243186951\n"
     ]
    }
   ],
   "source": [
    "score = mod.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}\\nTest Acc: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ambulance', 'crocodile', 'eye', 'flamingo', 'harp', 'mermaid', 'raccoon', 'rifle', 'snail', 'stethoscope']\n",
      "Predicted       Actual\n",
      "----------------------\n",
      "flamingo        flamingo\n",
      "rifle           rifle\n",
      "mermaid         mermaid\n",
      "ambulance       ambulance\n",
      "harp            raccoon\n",
      "mermaid         mermaid\n",
      "harp            harp\n",
      "ambulance       eye\n",
      "harp            harp\n",
      "harp            harp\n",
      "stethoscope     stethoscope\n",
      "harp            harp\n",
      "harp            rifle\n",
      "rifle           rifle\n",
      "crocodile       eye\n",
      "flamingo        flamingo\n",
      "eye             crocodile\n",
      "harp            harp\n",
      "flamingo        stethoscope\n",
      "flamingo        stethoscope\n"
     ]
    }
   ],
   "source": [
    "print(categories)\n",
    "print('Predicted       Actual')\n",
    "print('----------------------')\n",
    "\n",
    "for _ in range(20):\n",
    "    t = np.random.randint(len(X_test))\n",
    "    x1 = X_test[t].reshape(1, DIM, DIM, 1)\n",
    "    p = mod.predict(x1)\n",
    "    print(f'{categories[np.argmax(p)]:15s} '\n",
    "          f'{categories[np.argmax(y_test[t])]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=./tb_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save('./QDrawModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = load_model('./QDrawModel.h5')\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted       Actual\n",
      "----------------------\n",
      "flamingo        flamingo\n",
      "snail           snail\n",
      "flamingo        flamingo\n",
      "rifle           rifle\n",
      "raccoon         raccoon\n",
      "ambulance       ambulance\n",
      "mermaid         mermaid\n",
      "ambulance       ambulance\n",
      "flamingo        flamingo\n",
      "crocodile       crocodile\n",
      "snail           snail\n",
      "crocodile       rifle\n",
      "rifle           rifle\n",
      "raccoon         raccoon\n",
      "ambulance       crocodile\n",
      "harp            stethoscope\n",
      "eye             eye\n",
      "mermaid         stethoscope\n",
      "rifle           rifle\n",
      "harp            mermaid\n"
     ]
    }
   ],
   "source": [
    "print('Predicted       Actual')\n",
    "print('----------------------')\n",
    "\n",
    "for _ in range(20):\n",
    "    t = np.random.randint(len(X_test))\n",
    "    x1 = X_test[t].reshape(1, DIM, DIM, 1)\n",
    "    p = mod.predict(x1)\n",
    "    print(f'{categories[np.argmax(p)]:15s} '\n",
    "          f'{categories[np.argmax(y_test[t])]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, data in zip(['X_train', 'y_train', 'X_test', 'y_test'],\n",
    "                          [X_train, y_train, X_test, y_test]):\n",
    "    with h5py.File(f'{filename}.h5', 'w') as hf:\n",
    "        hf.create_dataset('QuickDraw', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read again (e.g.):\n",
    "hf = h5py.File('y_test.h5', 'r')\n",
    "y_test = np.array(hf['QuickDraw'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
