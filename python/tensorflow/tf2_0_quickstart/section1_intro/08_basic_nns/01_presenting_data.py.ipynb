{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from   tensorflow.python.keras.datasets import fashion_mnist\n",
    "\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Arrays with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items = 11\n",
    "n_list1 = np.arange(n_items)\n",
    "n_list2 = np.arange(n_items, n_items*2)\n",
    "n_list1, n_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_list1_dataset = tf.data.Dataset.from_tensor_slices(n_list1)\n",
    "n_list1_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.IteratorV2 at 0x1375fe150>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = tf.compat.v1.data.make_one_shot_iterator(n_list1_dataset)\n",
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for item in n_list1_dataset:\n",
    "    n = iterator.get_next().numpy()\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[3 4 5]\n",
      "[6 7 8]\n",
      "[ 9 10]\n"
     ]
    }
   ],
   "source": [
    "n_list1_dataset = tf.data.Dataset\\\n",
    "    .from_tensor_slices(n_list1)\\\n",
    "    .batch(3, drop_remainder=False)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(n_list1_dataset)\n",
    "for i in n_list1_dataset:\n",
    "    n = iterator.get_next().numpy()\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=75, shape=(), dtype=int32, numpy=1>, <tf.Tensor: id=76, shape=(), dtype=string, numpy=b'a'>)\n",
      "(<tf.Tensor: id=79, shape=(), dtype=int32, numpy=2>, <tf.Tensor: id=80, shape=(), dtype=string, numpy=b'e'>)\n",
      "(<tf.Tensor: id=83, shape=(), dtype=int32, numpy=3>, <tf.Tensor: id=84, shape=(), dtype=string, numpy=b'i'>)\n",
      "(<tf.Tensor: id=87, shape=(), dtype=int32, numpy=4>, <tf.Tensor: id=88, shape=(), dtype=string, numpy=b'o'>)\n",
      "(<tf.Tensor: id=91, shape=(), dtype=int32, numpy=5>, <tf.Tensor: id=92, shape=(), dtype=string, numpy=b'u'>)\n"
     ]
    }
   ],
   "source": [
    "ds1 = [1, 2, 3, 4, 5]\n",
    "ds2 = ['a', 'e', 'i', 'o', 'u']\n",
    "ds1 = tf.data.Dataset.from_tensor_slices(ds1)\n",
    "ds2 = tf.data.Dataset.from_tensor_slices(ds2)\n",
    "zipped_ds = tf.data.Dataset.zip((ds1, ds2))\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(zipped_ds)\n",
    "for i in zipped_ds:\n",
    "    n = iterator.get_next()\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ConcatenateDataset shapes: (), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "ds1 = tf.data.Dataset.from_tensor_slices([1, 2, 3, 5])\n",
    "ds2 = tf.data.Dataset.from_tensor_slices([19, 23, 29])\n",
    "ds3 = ds1.concatenate(ds2)\n",
    "print(ds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "tf.Tensor(29, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "iterator = tf.compat.v1.data.make_one_shot_iterator(ds3)\n",
    "for i in range(7):\n",
    "    n = iterator.get_next()\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "tf.Tensor(29, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(23, shape=(), dtype=int32)\n",
      "tf.Tensor(29, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for e in range(epochs):\n",
    "    for i in ds3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.14159</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.17100</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.80</td>\n",
       "      <td>dirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12345</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.32</td>\n",
       "      <td>daliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a    b      c          d\n",
       "0  3.14159  0.1   1.20       dogs\n",
       "1  2.17100  1.2   4.80       dirt\n",
       "2  0.12345  3.5  16.32  daliances"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a test file\n",
    "df = pd.DataFrame({'a': [3.14159, 2.171, 0.12345], \n",
    "                   'b': [0.1, 1.2, 3.5],\n",
    "                   'c': [1.2, 4.8, 16.32],\n",
    "                   'd': ['dogs', 'dirt', 'daliances']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=150, shape=(), dtype=float32, numpy=3.14159>, <tf.Tensor: id=151, shape=(), dtype=float32, numpy=1.2>)\n",
      "(<tf.Tensor: id=152, shape=(), dtype=float32, numpy=2.171>, <tf.Tensor: id=153, shape=(), dtype=float32, numpy=4.8>)\n",
      "(<tf.Tensor: id=154, shape=(), dtype=float32, numpy=0.12345>, <tf.Tensor: id=155, shape=(), dtype=float32, numpy=16.32>)\n"
     ]
    }
   ],
   "source": [
    "filename = ['./test.csv']\n",
    "record_defaults = [tf.float32] * 2\n",
    "dataset = tf.data.experimental.CsvDataset(\n",
    "    filename, record_defaults, header=True, select_cols=[0, 2]) # a&c only\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14159 1.2 dogs\n",
      "2.171 4.8 dirt\n",
      "0.12345 16.32 daliances\n"
     ]
    }
   ],
   "source": [
    "record_defaults += [tf.string]\n",
    "dataset = tf.data.experimental.CsvDataset(\n",
    "    filename, record_defaults, header=True, select_cols=[0, 2, 3])\n",
    "for item in dataset:\n",
    "    print(item[0].numpy(), item[1].numpy(), item[2].numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecords (binaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([0., 1., 2., 3., 4., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_tfrecord(fname, data):\n",
    "    writer = tf.io.TFRecordWriter(fname)\n",
    "    feature = {}\n",
    "    feature['data'] = tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data))\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(feature=feature))\n",
    "    serialized = example.SerializeToString()\n",
    "    writer.write(serialized)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_to_tfrecord('./trf_test.tfrecords', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\u0000\u0000\u0000\u0000\u0000\u0000\u0000�p\u0016J\r\n",
      "&\r\n",
      "$\r\n",
      "\u0004data\u0012\u001c",
      "\u0012\u001a\r\n",
      "\u0018\u0000\u0000\u0000\u0000\u0000\u0000�?\u0000\u0000\u0000@\u0000\u0000@@\u0000\u0000�@\u0000\u0000�@ݖ�!"
     ]
    }
   ],
   "source": [
    "!cat trf_test.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset('./trf_test.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr(proto):\n",
    "    keys_to_features = {\n",
    "        'data': tf.io.FixedLenSequenceFeature(\n",
    "            [], dtype=tf.float32, allow_missing=True)}\n",
    "    parsed = tf.io.parse_single_example(serialized=proto, \n",
    "                                        features=keys_to_features)\n",
    "    return parsed['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 1. 2. 3. 4. 5.], shape=(6,), dtype=float32)\n",
      "[0. 1. 2. 3. 4. 5.]\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(parse_tfr)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "# array retrieved as one item\n",
    "item = iterator.get_next()\n",
    "print(item)\n",
    "print(item.numpy())\n",
    "print(item[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './trf_test2.tfrecords'\n",
    "data = {'ID': 12345,\n",
    "        'Name': ['Bob', 'Dobolina'],\n",
    "        'Scores': [0., 0., 27.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = tf.train.Feature(int64_list=tf.train.Int64List(value=[data['ID']]))\n",
    "Name = tf.train.Feature(\n",
    "    bytes_list=tf.train.BytesList(\n",
    "        value=[n.encode('utf-8') for n in data['Name']]))\n",
    "Scores = tf.train.Feature(\n",
    "    float_list=tf.train.FloatList(value=data['Scores']))\n",
    "example = tf.train.Example(\n",
    "    features=tf.train.Features(\n",
    "        feature={'ID': ID, 'Name': Name, 'Scores': Scores}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.io.TFRecordWriter(filename)\n",
    "writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr2(proto):\n",
    "    keys_to_features = {'ID': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "                        'Name': tf.io.VarLenFeature(dtype=tf.string),\n",
    "                        'Scores': tf.io.VarLenFeature(dtype=tf.float32)}\n",
    "    parsed = tf.io.parse_single_example(serialized=proto, \n",
    "                                        features=keys_to_features)\n",
    "    return parsed['ID'], parsed['Name'], parsed['Scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\nE\\n\\x0c\\n\\x02ID\\x12\\x06\\x1a\\x04\\n\\x02\\xb9`\\n\\x1a\\n\\x06Scores\\x12\\x10\\x12\\x0e\\n\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x9a\\x99\\xddA\\n\\x19\\n\\x04Name\\x12\\x11\\n\\x0f\\n\\x03Bob\\n\\x08Dobolina', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset.map(parse_tfr2)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "item = iterator.get_next()\n",
    "# record retrieved as single item\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..huh... not quite right...\n",
    "#print('ID:', item[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 5\n",
    "y_1hot = tf.one_hot(y, depth=10).numpy()\n",
    "y_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 28, 28\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "split = 50000\n",
    "(y_train, y_valid) = y_train[:split], y_train[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1h = tf.one_hot(y_train, depth=n_classes).numpy()\n",
    "y_valid_1h = tf.one_hot(y_valid, depth=n_classes).numpy()\n",
    "y_test_1h  = tf.one_hot(y_test,  depth=n_classes).numpy()\n",
    "\n",
    "i = 5\n",
    "y_train[i], y_train_1h[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
