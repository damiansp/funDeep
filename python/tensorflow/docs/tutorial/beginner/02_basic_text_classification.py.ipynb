{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "palestinian-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras import Sequential\n",
    "from   tensorflow.keras import layers, losses, preprocessing\n",
    "from   tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Embedding, GlobalAveragePooling1D as GAP)\n",
    "from   tensorflow.keras.layers.experimental.preprocessing import (\n",
    "    TextVectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-egyptian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "foster-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../../../../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floral-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "subdir = 'aclIMDB'\n",
    "# BROKEN: requires certificate validation--downloading manually:\n",
    "#dataset = tf.keras.utils.get_file(\n",
    "#    'aclImdb_v1', url, untar=True, cache_dir=DATA, cache_subdir=subdir)\n",
    "#dataset_dir = os.path.join(os.path.dirname(dataset), subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "decent-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdbEr.txt', 'test', 'imdb.vocab', 'README', 'train']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = f'{DATA}/{subdir}'\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sophisticated-millennium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urls_unsup.txt',\n",
       " 'neg',\n",
       " 'urls_pos.txt',\n",
       " 'urls_neg.txt',\n",
       " 'pos',\n",
       " 'unsupBow.feat',\n",
       " 'labeledBow.feat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worst-omaha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(train_dir, 'pos/1181_9.txt')\n",
    "\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-devon",
   "metadata": {},
   "source": [
    "Using `text_dataset_from_directory` util, expects directory structure:\n",
    "```\n",
    "main_dir/\n",
    "  class_a/\n",
    "    a_text_1.txt\n",
    "    a_text_2.txt\n",
    "    ...\n",
    "  class_b/\n",
    "    b_text_1.txt\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "widespread-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_dir = os.path.join(train_dir, 'unsup')\n",
    "#shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appropriate-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "BATCH = 32\n",
    "SEED = 1103\n",
    "\n",
    "raw_training_ds = preprocessing.text_dataset_from_directory(\n",
    "    train_dir, \n",
    "    batch_size=BATCH, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "parallel-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      " b\"Curly Sue is a 6 year old with an abundance of hair and a life as a drifter. She and her father, Bill (Jim Belushi), try to survive on the streets by being small time con artists. In Chicago, Bill decides to jump in front of a car in a pricey parking garage while Curly will scream about lawsuits and traction to the intended victim. It happens to be a very upscale lawyer named Grey (Kelly Lynch) who is appropriately appalled at what she has done. Not only do the scammers make some cash, they get to spend the night at Grey's plush apartment. Even then, Grey feels she owes them more so the three of them hang together for a spell. Grey only knows the lucrative law business and nothing about life. Who better to teach her than Bill and Curly, those savvy experts on life's realities? But, all good things must come to an end and there is no life for a legal expert and a couple of con men. Or is there? This is a sweet and funny movie about the unexpected. Curly is certainly as entertaining as Shirley Temple but much edgier, of course. Belushi gives a rare touching performance as the down on his luck con and Lynch is luminous as the snooty but soft touch lawyer. John Hughes, as writer and director, shows us his magic touch once again, as the script is lively and unpredictable. Just watch Curly and Bill take Grey out for a night, with no money, and see the humorous results. Do you long for happy endings, long promised and finally delivered, with a few uncertain moments in between? This is your made-to-order movie.\"\n",
      "Label: 1\n",
      "Review:\n",
      " b\"This has to be some of the worst direction I've seen. The close-up can be a very powerful shot, but when every scene consists of nothing but close-ups, it loses all its impact. <br /><br />Tony Scott has some very beautiful scenery to work with, the backdrops of Mexico, the cantinas, the beautiful estate where Anthony Quinn lives, and the dusty towns Costner rolls through on his journey for revenge. Unfortunately we only catch quick glimpses of these places before the camera cuts to a picture of a big, giant head. Even the transition scenes where Costner is driving alone across Mexico quickly cut to a close-up. <br /><br />The score is over-dramatic and intrusive, dictating every emotion we should feel. The story itself should have been handled much better. Among other things, too many people pop up out of nowhere to help Costner along - it's just bad writing. <br /><br />It's a typical thriller storyline, but many others have taken the same premise and done outstanding things with it. Costner's No Way Out had a somewhat similar storyline, but it was a much better movie. <br /><br />The ending was completely anticlimactic and suffered from the most melodramatic scoring of the film. This movie was never going to be great, but if we saw more of Mexico and less of giant heads this film might have been watchable.\"\n",
      "Label: 0\n",
      "Review:\n",
      " b'You may say to yourself, \"Don Johnson as Elvis? Can that work? Is it possible? Seems like an terrible choice to me, but perhaps I should have an open mind. Maybe I\\'ll be surprised. Maybe he can pull it off.\"<br /><br />NOT!<br /><br />Don Johnson is not a bad actor. But he is an awful Elvis. He\\'s too short, too weak-voiced, too sharply featured ... well you\\'ve already imagined how bad he would be. Add to that a hokey black wig and heavy-handed eye-liner and mascara and it\\'s a big fat embarrassing mess.<br /><br />The best I can say is that since Johnson\\'s acting is decent and since his impersonation is so far off, after a while you don\\'t even think of him as Elvis anymore. You see him as some other crazed pop star instead. Then, on that level, the movie becomes watchable.<br /><br />Stephanie Zimbalist is also not ideally cast as the tall, beauty queen, Linda Thompson. But she is attractive in her own right and plays the part with the honesty, elegance and intelligence we\\'ve come to expect from all her roles. There may be too much intelligence in her performance. You have to be kind of a dope to stick with a dope abusing dope.<br /><br />There\\'s nothing new to this story; we\\'ve heard it many times before. If you\\'ve looking for new info or insight, you won\\'t find it. It\\'s told as a love story - an unrequited one: Linda for Elvis and Elvis for drugs.'\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_training_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print('Review:\\n', text_batch.numpy()[i])\n",
    "        print('Label:', label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "functioning-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to neg\n",
      "Label 1 corresponds to pos\n"
     ]
    }
   ],
   "source": [
    "for encoding in [0, 1]:\n",
    "    print(f'Label {encoding} corresponds to '\n",
    "          f'{raw_training_ds.class_names[encoding]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sustainable-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    f'{DATA}/aclIMDB/train', batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "awful-reverse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    f'{DATA}/aclIMDB/test', batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rising-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "assured-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10_000\n",
    "SEQ_LEN = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "minute-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(standardize=custom_standardization, \n",
    "                                    max_tokens=MAX_FEATURES,\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "medical-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make text-only dataset (no labes), then adapt()\n",
    "train_text = raw_training_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "minus-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "optical-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reveiw:\n",
      "b'As a collector of movie memorabilia, I had to buy the movie poster for this film which, now that I\\'ve finally seen it, has to be the best thing about it. There\\'s nothing more attractive to hang on your wall than a 27x41 inch image of the melting man. However, there\\'s nothing more awful to put in your VCR than an hour and a half long image of the melting man. At first I thought this movie was pure garbage but then I realized that it did have some qualities which made me laugh. The character of Dr. Ted Nelson has to be the most wishy-washy persona ever brought to the big screen. His dialogue is so trite it\\'s unbelievable! (\"It\\'s incredible! He seems to be getting stronger as he melts!)<br /><br />And could somebody tell me please how the heck they know exactly how much time Steve has left before he melts completely and exactly what their plan is to \"help\" him? If this movie was meant to scare its audience, I think it missed its calling.'\n",
      "Label: pos\n",
      "Vectorized review:\n",
      "(<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
      "array([[  14,    3, 8934,    5,   17,    1,   11,   66,    6,  817,    2,\n",
      "          17, 4054,   15,   10,   19,   60,  147,   12,  192,  411,  106,\n",
      "           9,   43,    6,   27,    2,  114,  150,   42,    9,  219,  157,\n",
      "          50, 1499,    6, 3382,   20,  123, 1574,   71,    3,    1, 9548,\n",
      "        1432,    5,    2, 3985,  131,  187,  219,  157,   50,  373,    6,\n",
      "         266,    8,  123, 7447,   71,   33,  559,    4,    3,  364,  203,\n",
      "        1432,    5,    2, 3985,  131,   30,   86,   11,  199,   10,   17,\n",
      "          13, 1038, 1181,   18,   90,   11, 1682,   12,    9,  116,   25,\n",
      "          46, 2512,   60,   91,   69,  468,    2,  108,    5,  884, 2705,\n",
      "        3034,   43,    6,   27,    2,   88,    1, 3434,  121,  792,    6,\n",
      "           2,  196,  280,   24,  391,    7,   37, 3005,   29, 1241,   29,\n",
      "        1034,   26,  182,    6,   27,  375, 3295,   14,   26,    1,    4,\n",
      "          95, 1771,  362,   69,  589,   87,    2, 2343,   34,  118,  594,\n",
      "          87,   72,   59, 1179,   43,  305,  153,   26,    1,  327,    4,\n",
      "         594,   48,   64, 1324,    7,    6,  326,   85,   44,   10,   17,\n",
      "          13,  942,    6, 2270,   29,  309,   11,  102,    9, 1033,   29,\n",
      "        2719,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# Get batch of reviews and labels from data set\n",
    "text_batch, label_batch = next(iter(raw_training_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(f'Reveiw:\\n{first_review}')\n",
    "print('Label:', raw_training_ds.class_names[first_label])\n",
    "print(f'Vectorized review:\\n{vectorize_text(first_review, first_label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pregnant-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1694 -> normally\n",
      "11 -> i\n",
      "89 -> dont\n",
      "Vocab size: 10000\n"
     ]
    }
   ],
   "source": [
    "for vec in [1694, 11, 89]:\n",
    "    print(f'{vec} -> {vectorize_layer.get_vocabulary()[vec]}')\n",
    "print('Vocab size:', len(vectorize_layer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dimensional-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_training_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "driven-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "secret-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "liable-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          320032    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 320,065\n",
      "Trainable params: 320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = Sequential([Embedding(MAX_FEATURES + 1, EMBED_DIM),\n",
    "                  Dropout(0.2),\n",
    "                  GAP(),\n",
    "                  Dropout(0.2),\n",
    "                  Dense(1)])\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "listed-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "            optimizer='adam',\n",
    "            metrics=tf.metrics.BinaryAccuracy(threshold=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "round-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.6753 - binary_accuracy: 0.6539 - val_loss: 0.5618 - val_binary_accuracy: 0.7992\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.5212 - binary_accuracy: 0.8103 - val_loss: 0.4173 - val_binary_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3947 - binary_accuracy: 0.8610 - val_loss: 0.3438 - val_binary_accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3289 - binary_accuracy: 0.8815 - val_loss: 0.3020 - val_binary_accuracy: 0.8890\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2880 - binary_accuracy: 0.8960 - val_loss: 0.2734 - val_binary_accuracy: 0.8980\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2576 - binary_accuracy: 0.9067 - val_loss: 0.2521 - val_binary_accuracy: 0.9055\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2346 - binary_accuracy: 0.9149 - val_loss: 0.2350 - val_binary_accuracy: 0.9124\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2168 - binary_accuracy: 0.9207 - val_loss: 0.2208 - val_binary_accuracy: 0.9176\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2014 - binary_accuracy: 0.9279 - val_loss: 0.2087 - val_binary_accuracy: 0.9232\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1865 - binary_accuracy: 0.9333 - val_loss: 0.1987 - val_binary_accuracy: 0.9272\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = mod.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-potato",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
