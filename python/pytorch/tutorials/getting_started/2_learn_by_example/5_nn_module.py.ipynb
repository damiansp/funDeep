{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "IN = 1000\n",
    "HIDDEN = 100\n",
    "OUT = 10\n",
    "\n",
    "ETA = 1e-4\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(BATCH, IN)\n",
    "y = torch.randn(BATCH, OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(IN, HIDDEN),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(HIDDEN, OUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: 645.52728\n",
      "  1: 602.45355\n",
      "  2: 564.39935\n",
      "  3: 530.20807\n",
      "  4: 499.60559\n",
      "  5: 471.88950\n",
      "  6: 446.51712\n",
      "  7: 423.47665\n",
      "  8: 401.96472\n",
      "  9: 381.63947\n",
      " 10: 362.37201\n",
      " 11: 344.16394\n",
      " 12: 326.86288\n",
      " 13: 310.47491\n",
      " 14: 294.89838\n",
      " 15: 280.03424\n",
      " 16: 265.86621\n",
      " 17: 252.29713\n",
      " 18: 239.28075\n",
      " 19: 226.79565\n",
      " 20: 214.80629\n",
      " 21: 203.33598\n",
      " 22: 192.36075\n",
      " 23: 181.88824\n",
      " 24: 171.85353\n",
      " 25: 162.27443\n",
      " 26: 153.13136\n",
      " 27: 144.41684\n",
      " 28: 136.11597\n",
      " 29: 128.23085\n",
      " 30: 120.71861\n",
      " 31: 113.58458\n",
      " 32: 106.79435\n",
      " 33: 100.37409\n",
      " 34: 94.29508\n",
      " 35: 88.56522\n",
      " 36: 83.17265\n",
      " 37: 78.09361\n",
      " 38: 73.32306\n",
      " 39: 68.82836\n",
      " 40: 64.61466\n",
      " 41: 60.65778\n",
      " 42: 56.92327\n",
      " 43: 53.41749\n",
      " 44: 50.13535\n",
      " 45: 47.06056\n",
      " 46: 44.18116\n",
      " 47: 41.48946\n",
      " 48: 38.97410\n",
      " 49: 36.62330\n",
      " 50: 34.42493\n",
      " 51: 32.35646\n",
      " 52: 30.42350\n",
      " 53: 28.61768\n",
      " 54: 26.93081\n",
      " 55: 25.35378\n",
      " 56: 23.87531\n",
      " 57: 22.48929\n",
      " 58: 21.19340\n",
      " 59: 19.97941\n",
      " 60: 18.84192\n",
      " 61: 17.77758\n",
      " 62: 16.77988\n",
      " 63: 15.84373\n",
      " 64: 14.96597\n",
      " 65: 14.14242\n",
      " 66: 13.36808\n",
      " 67: 12.64007\n",
      " 68: 11.95732\n",
      " 69: 11.31655\n",
      " 70: 10.71294\n",
      " 71: 10.14381\n",
      " 72: 9.60525\n",
      " 73: 9.09742\n",
      " 74: 8.61304\n",
      " 75: 8.15687\n",
      " 76: 7.72630\n",
      " 77: 7.32115\n",
      " 78: 6.93763\n",
      " 79: 6.57586\n",
      " 80: 6.23433\n",
      " 81: 5.91185\n",
      " 82: 5.60786\n",
      " 83: 5.32100\n",
      " 84: 5.04953\n",
      " 85: 4.79266\n",
      " 86: 4.54985\n",
      " 87: 4.32036\n",
      " 88: 4.10291\n",
      " 89: 3.89696\n",
      " 90: 3.70209\n",
      " 91: 3.51756\n",
      " 92: 3.34268\n",
      " 93: 3.17716\n",
      " 94: 3.02036\n",
      " 95: 2.87167\n",
      " 96: 2.73119\n",
      " 97: 2.59811\n",
      " 98: 2.47189\n",
      " 99: 2.35214\n",
      "100: 2.23847\n",
      "101: 2.13058\n",
      "102: 2.02813\n",
      "103: 1.93096\n",
      "104: 1.83864\n",
      "105: 1.75106\n",
      "106: 1.66782\n",
      "107: 1.58875\n",
      "108: 1.51370\n",
      "109: 1.44251\n",
      "110: 1.37492\n",
      "111: 1.31059\n",
      "112: 1.24939\n",
      "113: 1.19124\n",
      "114: 1.13589\n",
      "115: 1.08320\n",
      "116: 1.03316\n",
      "117: 0.98563\n",
      "118: 0.94034\n",
      "119: 0.89727\n",
      "120: 0.85625\n",
      "121: 0.81725\n",
      "122: 0.78020\n",
      "123: 0.74489\n",
      "124: 0.71127\n",
      "125: 0.67922\n",
      "126: 0.64867\n",
      "127: 0.61958\n",
      "128: 0.59184\n",
      "129: 0.56540\n",
      "130: 0.54019\n",
      "131: 0.51619\n",
      "132: 0.49329\n",
      "133: 0.47143\n",
      "134: 0.45057\n",
      "135: 0.43067\n",
      "136: 0.41169\n",
      "137: 0.39363\n",
      "138: 0.37640\n",
      "139: 0.35996\n",
      "140: 0.34427\n",
      "141: 0.32930\n",
      "142: 0.31500\n",
      "143: 0.30136\n",
      "144: 0.28834\n",
      "145: 0.27589\n",
      "146: 0.26401\n",
      "147: 0.25264\n",
      "148: 0.24177\n",
      "149: 0.23139\n",
      "150: 0.22147\n",
      "151: 0.21201\n",
      "152: 0.20297\n",
      "153: 0.19432\n",
      "154: 0.18605\n",
      "155: 0.17814\n",
      "156: 0.17058\n",
      "157: 0.16337\n",
      "158: 0.15646\n",
      "159: 0.14986\n",
      "160: 0.14355\n",
      "161: 0.13751\n",
      "162: 0.13174\n",
      "163: 0.12622\n",
      "164: 0.12095\n",
      "165: 0.11590\n",
      "166: 0.11106\n",
      "167: 0.10644\n",
      "168: 0.10201\n",
      "169: 0.09777\n",
      "170: 0.09371\n",
      "171: 0.08983\n",
      "172: 0.08612\n",
      "173: 0.08256\n",
      "174: 0.07916\n",
      "175: 0.07590\n",
      "176: 0.07279\n",
      "177: 0.06980\n",
      "178: 0.06695\n",
      "179: 0.06421\n",
      "180: 0.06159\n",
      "181: 0.05908\n",
      "182: 0.05669\n",
      "183: 0.05440\n",
      "184: 0.05221\n",
      "185: 0.05011\n",
      "186: 0.04810\n",
      "187: 0.04617\n",
      "188: 0.04432\n",
      "189: 0.04255\n",
      "190: 0.04085\n",
      "191: 0.03923\n",
      "192: 0.03767\n",
      "193: 0.03617\n",
      "194: 0.03474\n",
      "195: 0.03337\n",
      "196: 0.03205\n",
      "197: 0.03079\n",
      "198: 0.02958\n",
      "199: 0.02842\n",
      "200: 0.02730\n",
      "201: 0.02623\n",
      "202: 0.02520\n",
      "203: 0.02422\n",
      "204: 0.02327\n",
      "205: 0.02237\n",
      "206: 0.02150\n",
      "207: 0.02067\n",
      "208: 0.01986\n",
      "209: 0.01910\n",
      "210: 0.01836\n",
      "211: 0.01765\n",
      "212: 0.01697\n",
      "213: 0.01632\n",
      "214: 0.01569\n",
      "215: 0.01509\n",
      "216: 0.01451\n",
      "217: 0.01396\n",
      "218: 0.01342\n",
      "219: 0.01291\n",
      "220: 0.01242\n",
      "221: 0.01195\n",
      "222: 0.01149\n",
      "223: 0.01106\n",
      "224: 0.01064\n",
      "225: 0.01023\n",
      "226: 0.00985\n",
      "227: 0.00948\n",
      "228: 0.00912\n",
      "229: 0.00878\n",
      "230: 0.00845\n",
      "231: 0.00813\n",
      "232: 0.00783\n",
      "233: 0.00753\n",
      "234: 0.00725\n",
      "235: 0.00698\n",
      "236: 0.00672\n",
      "237: 0.00647\n",
      "238: 0.00623\n",
      "239: 0.00600\n",
      "240: 0.00578\n",
      "241: 0.00556\n",
      "242: 0.00536\n",
      "243: 0.00516\n",
      "244: 0.00497\n",
      "245: 0.00478\n",
      "246: 0.00461\n",
      "247: 0.00444\n",
      "248: 0.00428\n",
      "249: 0.00412\n",
      "250: 0.00397\n",
      "251: 0.00382\n",
      "252: 0.00368\n",
      "253: 0.00355\n",
      "254: 0.00342\n",
      "255: 0.00330\n",
      "256: 0.00318\n",
      "257: 0.00306\n",
      "258: 0.00295\n",
      "259: 0.00284\n",
      "260: 0.00274\n",
      "261: 0.00264\n",
      "262: 0.00255\n",
      "263: 0.00245\n",
      "264: 0.00237\n",
      "265: 0.00228\n",
      "266: 0.00220\n",
      "267: 0.00212\n",
      "268: 0.00204\n",
      "269: 0.00197\n",
      "270: 0.00190\n",
      "271: 0.00183\n",
      "272: 0.00177\n",
      "273: 0.00170\n",
      "274: 0.00164\n",
      "275: 0.00158\n",
      "276: 0.00153\n",
      "277: 0.00147\n",
      "278: 0.00142\n",
      "279: 0.00137\n",
      "280: 0.00132\n",
      "281: 0.00128\n",
      "282: 0.00123\n",
      "283: 0.00119\n",
      "284: 0.00115\n",
      "285: 0.00111\n",
      "286: 0.00107\n",
      "287: 0.00103\n",
      "288: 0.00099\n",
      "289: 0.00096\n",
      "290: 0.00093\n",
      "291: 0.00089\n",
      "292: 0.00086\n",
      "293: 0.00083\n",
      "294: 0.00080\n",
      "295: 0.00078\n",
      "296: 0.00075\n",
      "297: 0.00072\n",
      "298: 0.00070\n",
      "299: 0.00067\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print('%3d: %.5f' % (i, loss.item()))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= ETA * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
