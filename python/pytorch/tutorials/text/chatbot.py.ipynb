{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From <a href=\"https://pytorch.org/tutorials/beginner/chatbot_tutorial.html\">Pytorch Tutorial</a> by Matthew Inkawhich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "from io import open\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.jit import script, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data \n",
    "### (Cornell Movie-Dialogues Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../../data'\n",
    "corpus_name = 'cornell movie-dialogs corpus'\n",
    "corpus = os.path.join(DATA, corpus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lines(file, n=10):\n",
    "    with open(file, 'rb') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "print_lines(os.path.join(corpus, 'movie_lines.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Formatted Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lines(file_name, fields):\n",
    "    '''Splits each line of the file into dict of fields'''\n",
    "    lines = {}\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            line_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                line_obj[field] = values[i]\n",
    "            lines[line_obj['lineID']] = line_obj\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations(file_name, lines, fields):\n",
    "    '''\n",
    "    Groups fields of lines from load_lines() into conversations based on\n",
    "    movie_conversations.txt\n",
    "    '''\n",
    "    conversations = []\n",
    "    with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            conv_obj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                conv_obj[field] = values[i]\n",
    "            line_ids = eval(conv_obj['utteranceIDs'])\n",
    "            conv_obj['lines'] = []\n",
    "            for line_id in line_ids:\n",
    "                conv_obj['lines'].append(lines[line_id])\n",
    "            conversations.append(conv_obj)\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence_pairs(conversations):\n",
    "    '''Extract pairs of sentences from conversations'''\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation['lines']) - 1):\n",
    "            input_line = conversation['lines'][i]['text'].strip()\n",
    "            target_line = conversation['lines'][i + 1]['text'].strip()\n",
    "            # Filter if one of the lists is empty\n",
    "            if input_line and target_line:\n",
    "                qa_pairs.append([input_line, target_line])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = os.path.join(corpus, 'formatted_movie_lines.txt')\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, 'unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\n",
    "    'lineID', 'characterID', 'movieID', 'character', 'text']\n",
    "MOVIE_CONVERSATION_FIELDS = [\n",
    "    'character1ID', 'character2ID', 'movieID', 'utteranceIDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n"
     ]
    }
   ],
   "source": [
    "print('\\nProcessing corpus...')\n",
    "lines = load_lines(os.path.join(corpus, 'movie_lines.txt'), \n",
    "                   MOVIE_LINES_FIELDS)\n",
    "\n",
    "print('\\nLoading conversations...')\n",
    "conversations = load_conversations(\n",
    "    os.path.join(corpus, 'movie_conversations.txt'), \n",
    "    lines,\n",
    "    MOVIE_CONVERSATION_FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing newly formatted file...\n"
     ]
    }
   ],
   "source": [
    "print('\\nWriting newly formatted file...')\n",
    "with open(datafile, 'w', encoding='utf-8') as out:\n",
    "    writer = csv.writer(out, delimiter=delimiter)\n",
    "    for pair in extract_sentence_pairs(conversations):\n",
    "        writer.writerow(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample lines from file\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\r\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "print('\\nSample lines from file')\n",
    "print_lines(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Trim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0 # to pad short sentences\n",
    "SOS = 1 # start of sentence\n",
    "EOS = 2 # end of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD: 'PAD', SOS: 'SOS', EOS: 'EOS'}\n",
    "        self.n_words = 3 # Count SOS, EOS, PAD\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split():\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    # Remove words below min count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), \n",
    "            len(self.word2index), \n",
    "            len(keep_words) / len(self.word2index)))\n",
    "        \n",
    "        # Reinit dicts\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD: 'PAD', SOS: 'SOS', EOS: 'EOS'}\n",
    "        self.n_words = 3\n",
    "        for word in keep_words:\n",
    "            self.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r'([.!?])', r' \\1', s)\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
    "    s = re.sub(r'\\s+', r' ', s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocs(datafile, corpus_name):\n",
    "    print('Reading lines...')\n",
    "    lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
    "    pairs = [[normalize_string(s) for s in line.split('\\t')] \n",
    "             for line in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pair(p):\n",
    "    return len(p[0].split()) < MAX_LEN and len(p[1].split()) < MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prep_data(corpus, corpus_name, datafile, save_dir):\n",
    "    print('Start prepping training data...')\n",
    "    voc, pairs = read_vocs(datafile, corpus_name)\n",
    "    print('Read {!s} sentence pairs'.format(len(pairs)))\n",
    "    pairs = filter_pairs(pairs)\n",
    "    print('Trimmed to {!s} sentence pairs'.format(len(pairs)))\n",
    "    print('Counting words...')\n",
    "    for pair in pairs:\n",
    "        voc.add_sentence(pair[0])\n",
    "        voc.add_sentence(pair[1])\n",
    "    print('Counted words:', voc.n_words)\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prepping training data...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 64271 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 3\n",
      "\n",
      "pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "save_dir = '%s/save' % DATA\n",
    "voc, pairs = load_prep_data(corpus, corpus_name, datafile, save_dir)\n",
    "print('\\npairs:')\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_rare_words(voc, pairs):\n",
    "    voc.trim(MIN_COUNT)\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        for word in input_sentence.split():\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        for word in output_sentence.split():\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "    print('Trimmed from {} pairs to {}, {:.4f} of total'.format(\n",
    "        len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7822 / 18004 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 0.8272 of total\n"
     ]
    }
   ],
   "source": [
    "pairs = trim_rare_words(voc, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_sentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split()] + [EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(l, fill_value=PAD):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fill_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_matrix(l, value=PAD):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_var(l, voc):\n",
    "    indices_batch = [indices_from_sentence(voc, sentence) \n",
    "                     for sentence in l]\n",
    "    lengths = torch.tensor([len(indices) for indices in indices_batch])\n",
    "    pad_list = zero_padding(indices_batch)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    return pad_var, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_var(l, voc):\n",
    "    indices_batch = [indices_from_sentence(voc, sentence) \n",
    "                     for sentence in l]\n",
    "    max_target_len = max([len(indices) for indices in indices_batch])\n",
    "    pad_list = zero_padding(indices_batch)\n",
    "    mask = binary_matrix(pad_list)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "    return pad_var, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch2train_data(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split()), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = input_var(input_batch, voc)\n",
    "    output, mask, max_target_len = output_var(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 2, 2],\n",
      "        [3, 3, 3, 0, 0],\n",
      "        [3, 3, 3, 0, 0],\n",
      "        [3, 2, 2, 0, 0],\n",
      "        [2, 0, 0, 0, 0]])\n",
      "lengths: tensor([8, 7, 7, 4, 4])\n",
      "target_variable: tensor([[3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 2],\n",
      "        [3, 2, 3, 3, 0],\n",
      "        [3, 0, 3, 3, 0],\n",
      "        [3, 0, 3, 3, 0],\n",
      "        [3, 0, 3, 3, 0],\n",
      "        [3, 0, 2, 3, 0],\n",
      "        [3, 0, 0, 3, 0],\n",
      "        [2, 0, 0, 2, 0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 0, 1, 1, 0],\n",
      "        [1, 0, 1, 1, 0],\n",
      "        [1, 0, 1, 1, 0],\n",
      "        [1, 0, 1, 1, 0],\n",
      "        [1, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 1, 0]], dtype=torch.uint8)\n",
      "max_target_len: 10\n"
     ]
    }
   ],
   "source": [
    "# Example for validataion\n",
    "BATCH = 5\n",
    "batches = batch2train_data(voc, \n",
    "                           [random.choice(pairs) for _ in range(BATCH)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print('input_variable:', input_variable)\n",
    "print('lengths:', lengths)\n",
    "print('target_variable:', target_variable)\n",
    "print('mask:', mask)\n",
    "print('max_target_len:', max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        # Init GRU; input_size and hidden_size are both set to \n",
    "        #   'hidden_size' bc input size is a word embedding wtih \n",
    "        #    n_features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size, \n",
    "                          n_layers, \n",
    "                          dropout=(0 if n_layers == 1 else dropout), \n",
    "                          bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lens, hidden=None):\n",
    "        # Word index -> embedding\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of seqs for RNN mod\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, \n",
    "                                                         input_lens)\n",
    "        # GRU forward pass\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequences(outputs)\n",
    "        # Sum bidirectional outputs\n",
    "        outputs = (outputs[:, :, :self.hidden_size] \n",
    "                   + outputs[:, :, self.hidden_size:])\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder (with Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \n",
    "                             'is not an appropriate attention method')\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nnLinear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hedden_size*2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "            \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "    \n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "    \n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(\n",
    "            torch.cat(\n",
    "                (hidden.expand(encoder_output.size(0), -1, -1),\n",
    "                 encoder_output),\n",
    "                2))\\\n",
    "            .tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) according to method\n",
    "        attn_energies = {\n",
    "            'general': self.general_score,\n",
    "            'concat': self.concat_score,\n",
    "            'dot': self.dot_score}[self.method](hidden, encoder_outputs)\n",
    "        # Transpose max_length and batch size dims\n",
    "        attn_energies = attn_energies.t()\n",
    "        # Return softmax normalized probs with added dim\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(\n",
    "            self, attn_model, embedding, hidden_size, output_size, \n",
    "            n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, \n",
    "                          hidden_size, \n",
    "                          n_layers, \n",
    "                          dropout=0 if n_layers == 1 else dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Runs one word at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(inpuy_step)\n",
    "        embedded = slef.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Attn weights for current GRU output\n",
    "        attn_weighs = self.attn(rnn_output, encoder_outputs)\n",
    "        # Mult attn weights and encoder out to get 'weighted sum' vec\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concat weighted ctxt vec and GRU out using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict with Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Final hidden state:\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training Procedure\n",
    "### Masked Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    n_total = mask.sum()\n",
    "    cross_ent = -torch.log(\n",
    "        torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = cross_ent.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, n_totel.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        input_var, lens, target_var, mask, max_target_len, encoder,\n",
    "        decoder, embedding, encoder_optimizer, decoder_optimizer, \n",
    "        batch_size, clip, max_len):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    input_var = input_var.to(device)\n",
    "    lens = lens.to(device)\n",
    "    target_var = target_var.to(device)\n",
    "    mask = mask.to(device)\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    # Forward pass\n",
    "    encoder_outputs, encoder_hidden = encoder(input_var, lens)\n",
    "    \n",
    "    # Init decoder input with SOS at start of each sent\n",
    "    decoder_input = torch.LongTensor([[SOS for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "    # Trigger init state from prev output\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    use_teacher_forcing = (True if random.random() < teacher_forcing_ratio \n",
    "                           else False)\n",
    "    # Forward through decoder\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_var[t].view(1, -1)\n",
    "            mask_loss, n_total = maskNLLLoss(\n",
    "                decoder_output, target_var[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * n_total)\n",
    "            n_totals += n_total\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # No teacher forcing: next input is deecoder's own output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([\n",
    "                [topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            mask_loss, n_total = maskNLLLoss(\n",
    "                decoder_output, target_var[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * n_total)\n",
    "            n_totals += n_total\n",
    "    \n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    # Adj weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iters(\n",
    "        mod_name, voc, pairs, encoder, decoder, encoder_optimizer, \n",
    "        decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers,\n",
    "        save_dir, n_iter, batch_size, print_every, save_every, clip,\n",
    "        corpus_name, load_file_name):\n",
    "    # Load batches\n",
    "    training_batches = [\n",
    "        batch2train_data(\n",
    "            voc, \n",
    "            [random.choice(pairs) for _ in range(batch_size)]) \n",
    "        for _ in range(n_iter)]\n",
    "    # Init\n",
    "    print('Initializing...')\n",
    "    start_iter = 1\n",
    "    print_loss = 0\n",
    "    if load_file_name:\n",
    "        start_iter = checkpoint['iteration'] + 1\n",
    "    # Train\n",
    "    print('Training...')\n",
    "    for i in range(start_iter, n_iter + 1):\n",
    "        training_batch = training_batches[i - 1]\n",
    "        # Extract fields from batch\n",
    "        input_var, lens, target_var, mask, max_target_len = training_batch\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(\n",
    "            input_var, lens, target_var, mask, max_target_len, encoder,\n",
    "            decoder, embedding, encoder_optimizer, decoder_optimizer, \n",
    "            batch_size, clip)\n",
    "        print_loss += loss\n",
    "        # Print progress\n",
    "        if i % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print('Iter: {}; Perc. completer: {:.1f}%; Avg. loss: {:.4f}'\\\n",
    "                  .format(i, i / n_iter * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "        # Save checkpoint\n",
    "        if i % save_every == 0:\n",
    "            directory = os.path.join(\n",
    "                save_dir, \n",
    "                mod_name, \n",
    "                corpus_name, \n",
    "                '{}-{}_{}'.format(\n",
    "                    encoder_n_layears, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torchs.save({'iteration': i,\n",
    "                         'en': encoder.state_dict(),\n",
    "                         'de': decoder.state_dict(),\n",
    "                         'en_opt': encoder_optimizer.state_dict(),\n",
    "                         'de_opt': decoder_optimizer.state_dict(),\n",
    "                         'loss': loss,\n",
    "                         'voc_dict': voc.__dict__,\n",
    "                         'embedding': embedding.state_dict()},\n",
    "                       os.path.join(directory, '{}_{}.tar'.format(\n",
    "                           i, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, input_seq, input_len, max_len):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, \n",
    "                                                       input_len)\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        decoder_input = (\n",
    "            torch.ones(1, 1, device=device, dtype=torch.long) * SOS)\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        for _ in range(max_len):\n",
    "            decoder_output, decoder_hidden = slef.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, \n",
    "                                                      dim=1)\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalauate(encoder, decoder, searcher, voc, sentence, max_len=MAX_LEN):\n",
    "    # words -> indices\n",
    "    index_batch = [indices_from_sentences(voc, sentence)]\n",
    "    lens = torch.tensor([len(indices) for indices in index_batch])\n",
    "    input_batch = torch.LongTensor(index_batch).transpose(0, 1)\n",
    "    input_batch = input_batch.to(device)\n",
    "    lens = lens.to(device)\n",
    "    # Decode\n",
    "    tokens, scores = searcher(input_batch, lens, max_len)\n",
    "    # ind -> word\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_input(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while True:\n",
    "        try:\n",
    "            input_sentence = input('> ')\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            input_sentence = normaliz_string(input_sentence)\n",
    "            output_words = evaluate(\n",
    "                encoder, decoder, searcher, voc, input_sentence)\n",
    "            output_words[:] = [\n",
    "                x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "        except KeyError:\n",
    "            print('Error: Encountered unknown word.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cb_model'\n",
    "attn_model = 'dot' # 'general', 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_filename = None\n",
    "chckpoint_iter = 4000\n",
    "#load_filename = os.path.join(\n",
    "#    save_dir, \n",
    "#    model_name, \n",
    "#    corpus_name, \n",
    "#    '{}-{}-{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#    '{}_checkpoint.tar'.format(checkpoint_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_filename:\n",
    "    checkpoint = torch.load(load_filename)\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimiser_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder...\n"
     ]
    }
   ],
   "source": [
    "print('Building encoder and decoder...')\n",
    "embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "if load_filename:\n",
    "    embedding.load_state_dict(embedding_sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(\n",
    "    attn_model, \n",
    "    embedding, \n",
    "    hidden_size, \n",
    "    voc.n_words, \n",
    "    decoder_n_layers, \n",
    "    dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready to go.\n"
     ]
    }
   ],
   "source": [
    "if load_filename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models ready to go.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
