{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up and Running with Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, display, HTML, Image\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can reset graph at any time (instead of rebooting jupyter) with:\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3, name = 'x')\n",
    "y = tf.Variable(4, name = 'y')\n",
    "f = x * x * y + y + 2\n",
    "\n",
    "s = tf.Session()\n",
    "s.run(x.initializer)\n",
    "s.run(y.initializer)\n",
    "res = s.run(f)\n",
    "print(res)\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Or\n",
    "with tf.Session() as s:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    res = f.eval()\n",
    "    \n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Or init all vars\n",
    "init = tf.global_variables_initializer() # preps an init node\n",
    "\n",
    "with tf.Session() as s:\n",
    "    init.run() # actual var initialization\n",
    "    res = f.eval()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "print(x1.graph is tf.get_default_graph())\n",
    "\n",
    "# Make new graph and temporarily set is as default\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle of a Node Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as s:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   8.30140000e+00,   2.10000000e+01,\n",
       "          6.23813708e+00,   9.71880492e-01,   2.40100000e+03,\n",
       "          2.10984183e+00,   3.78600000e+01,  -1.22220000e+02],\n",
       "       [  1.00000000e+00,   7.25740000e+00,   5.20000000e+01,\n",
       "          8.28813559e+00,   1.07344633e+00,   4.96000000e+02,\n",
       "          2.80225989e+00,   3.78500000e+01,  -1.22240000e+02],\n",
       "       [  1.00000000e+00,   5.64310000e+00,   5.20000000e+01,\n",
       "          5.81735160e+00,   1.07305936e+00,   5.58000000e+02,\n",
       "          2.54794521e+00,   3.78500000e+01,  -1.22250000e+02],\n",
       "       [  1.00000000e+00,   3.84620000e+00,   5.20000000e+01,\n",
       "          6.28185328e+00,   1.08108108e+00,   5.65000000e+02,\n",
       "          2.18146718e+00,   3.78500000e+01,  -1.22250000e+02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "housing_data_plus_bias[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "XT = tf.transpose(X)\n",
    "# Normal equation: Theta = (X.TX)^-1X.Ty\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as s:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# First scale features\n",
    "scaled_housing = StandardScaler().fit_transform(housing.data)\n",
    "scaled_housing_bias = np.c_[np.ones((m, 1)), scaled_housing]\n",
    "\n",
    "# Sklearn Regression model for comparison:\n",
    "lm = LinearRegression()\n",
    "lm.fit(scaled_housing, housing.target.reshape(-1, 1))\n",
    "\n",
    "#np.r_?\n",
    "\n",
    "print(np.r_[lm.intercept_.reshape(-1, 1), lm.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually Computing the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0\tMSE = 6.0242\n",
      "Epoch  400\tMSE = 0.6259\n",
      "Epoch  800\tMSE = 0.5638\n",
      "Epoch 1200\tMSE = 0.5408\n",
      "Epoch 1600\tMSE = 0.5315\n",
      "Epoch 2000\tMSE = 0.5276\n",
      "Epoch 2400\tMSE = 0.5259\n",
      "Epoch 2800\tMSE = 0.5250\n",
      "Epoch 3200\tMSE = 0.5247\n",
      "Epoch 3600\tMSE = 0.5245\n",
      "[[ 2.06855249]\n",
      " [ 0.83938348]\n",
      " [ 0.1207923 ]\n",
      " [-0.28358203]\n",
      " [ 0.32045361]\n",
      " [-0.00388739]\n",
      " [-0.03970707]\n",
      " [-0.8758412 ]\n",
      " [-0.84761393]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 4000 # iterations of (batch) GD\n",
    "eta = 0.01      # learning rate\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_housing_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1.), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "# assign() updates theta\n",
    "training_op = tf.assign(theta, theta - eta * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch %4d\\tMSE = %.4f' %(epoch, mse.eval()))\n",
    "        s.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta) # Note: vals differ from above b/c of scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using TF's `autodiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0\tMSE = 13.5263\n",
      "Epoch  400\tMSE = 0.6515\n",
      "Epoch  800\tMSE = 0.5590\n",
      "Epoch 1200\tMSE = 0.5338\n",
      "Epoch 1600\tMSE = 0.5270\n",
      "Epoch 2000\tMSE = 0.5251\n",
      "Epoch 2400\tMSE = 0.5245\n",
      "Epoch 2800\tMSE = 0.5244\n",
      "Epoch 3200\tMSE = 0.5243\n",
      "Epoch 3600\tMSE = 0.5243\n",
      "[[ 2.06855249]\n",
      " [ 0.82750708]\n",
      " [ 0.11875076]\n",
      " [-0.26079711]\n",
      " [ 0.30146012]\n",
      " [-0.00447591]\n",
      " [-0.0392811 ]\n",
      " [-0.90187538]\n",
      " [-0.87224895]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 4000 # iterations of (batch) GD\n",
    "eta = 0.01      # learning rate\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_housing_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1.), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "# assign() updates theta\n",
    "training_op = tf.assign(theta, theta - eta * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch %4d\\tMSE = %.4f' %(epoch, mse.eval()))\n",
    "        s.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta) # Note: Converges to same degree of accuracy sooner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0\tMSE = 11.6607\n",
      "Epoch  400\tMSE = 0.5677\n",
      "Epoch  800\tMSE = 0.5435\n",
      "Epoch 1200\tMSE = 0.5331\n",
      "Epoch 1600\tMSE = 0.5284\n",
      "Epoch 2000\tMSE = 0.5263\n",
      "Epoch 2400\tMSE = 0.5253\n",
      "Epoch 2800\tMSE = 0.5248\n",
      "Epoch 3200\tMSE = 0.5245\n",
      "Epoch 3600\tMSE = 0.5244\n",
      "[[ 2.06855249]\n",
      " [ 0.83746254]\n",
      " [ 0.12030237]\n",
      " [-0.28019547]\n",
      " [ 0.31775993]\n",
      " [-0.00404068]\n",
      " [-0.03962468]\n",
      " [-0.88121635]\n",
      " [-0.85277724]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 4000 # iterations of (batch) GD\n",
    "eta = 0.01      # learning rate\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.constant(scaled_housing_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1.), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = eta)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 400 == 0:\n",
    "            print('Epoch %4d\\tMSE = %.4f' %(epoch, mse.eval()))\n",
    "        s.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding Data to the Training Algorithm\n",
    "Modify code to run as mini-batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "# Using placeholders\n",
    "# 'None' allows any no. of rows:\n",
    "A = tf.placeholder(tf.float32, shape = (None, 3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as s:\n",
    "    B1 = B.eval(feed_dict = { A: [[1, 2, 3]] })\n",
    "    B2 = B.eval(feed_dict = { A: [[4, 5, 6], \n",
    "                                  [7, 8, 9]] })\n",
    "    \n",
    "print(B1)\n",
    "print(B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    rnd.seed(epoch * n_batches + batch_index)\n",
    "    indices = rnd.randint(m, size = batch_size)\n",
    "    X_batch = scaled_housing_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      " [[ 2.06604695]\n",
      " [ 0.84577423]\n",
      " [ 0.11162421]\n",
      " [-0.27690282]\n",
      " [ 0.28115126]\n",
      " [-0.02072373]\n",
      " [-0.06640353]\n",
      " [-0.8829757 ]\n",
      " [-0.85721791]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 40 # iterations of (batch) GD\n",
    "eta = 0.01      # learning rate\n",
    "\n",
    "m, n = housing.data.shape\n",
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = 'X')\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1., seed = 42), \n",
    "                    name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = eta)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            s.run(training_op, feed_dict = { X: X_batch, y: y_batch })\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print('Best theta:\\n', best_theta) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1., seed = 42), \n",
    "                    name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = eta)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0\tMSE: 2.7544\n",
      "Epoch: 100\tMSE: 0.6322\n",
      "Epoch: 200\tMSE: 0.5728\n",
      "Epoch: 300\tMSE: 0.5585\n",
      "Epoch: 400\tMSE: 0.5491\n",
      "Epoch: 500\tMSE: 0.5423\n",
      "Epoch: 600\tMSE: 0.5374\n",
      "Epoch: 700\tMSE: 0.5338\n",
      "Epoch: 800\tMSE: 0.5312\n",
      "Epoch: 900\tMSE: 0.5294\n",
      "Best theta:\n",
      " [[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch: %3d\\tMSE: %.4f' %(epoch, mse.eval()))\n",
    "            save_path = saver.save(s, '/tmp/ch09_mod.ckpt')\n",
    "        s.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(s, 'ch09_final_mod.ckpt')\n",
    "    \n",
    "print('Best theta:\\n', best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch09_final_mod.ckpt.data-00000-of-00001\r\n",
      "ch09_final_mod.ckpt.index\r\n",
      "ch09_final_mod.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls | grep 'mod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/ch09_mod.ckpt\n",
      "Epoch:   0\tMSE: 2.7544\n",
      "Epoch: 100\tMSE: 0.6322\n",
      "Epoch: 200\tMSE: 0.5728\n",
      "Epoch: 300\tMSE: 0.5585\n",
      "Epoch: 400\tMSE: 0.5491\n",
      "Epoch: 500\tMSE: 0.5423\n",
      "Epoch: 600\tMSE: 0.5374\n",
      "Epoch: 700\tMSE: 0.5338\n",
      "Epoch: 800\tMSE: 0.5312\n",
      "Epoch: 900\tMSE: 0.5294\n",
      "Best theta:\n",
      " [[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Load a saved model\n",
    "with tf.Session() as s:\n",
    "    saver.restore(s, '/tmp/ch09_mod.ckpt')\n",
    "    s.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch: %3d\\tMSE: %.4f' %(epoch, mse.eval()))\n",
    "            save_path = saver.save(s, '/tmp/ch09_mod.ckpt')\n",
    "        s.run(training_op)\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(s, 'ch09_final_mod.ckpt')\n",
    "    \n",
    "print('Best theta:\\n', best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Graph in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_consts(graph_def, max_const_size = 32):\n",
    "    '''Strip large constant values from graph_def'''\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add()\n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b'<stripped %d bytes>'%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size = 32):\n",
    "    '''Visualize TF graph'''\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size = max_const_size)\n",
    "    code = '''\n",
    "      <script>\n",
    "        function load() {{\n",
    "          document.getElementById('{id}').pbtxt = {data};\n",
    "        }}\n",
    "      </script>\n",
    "      <link \n",
    "         rel=\"import\" \n",
    "         href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\"\n",
    "         onload=load() />\n",
    "      <div style=\"height:600px\">\n",
    "        <tf-graph-basic id=\"{id}\"><t/tf-graph-basic>\n",
    "      </div>\n",
    "    '''.format(data = repr(str(strip_def)), \n",
    "               id = 'graph' + str(np.random.rand()))\n",
    "    iframe = '''\n",
    "      <iframe seamless style=\"width:1200px;height:620px;border:0\" \n",
    "              srcdoc=\"{}\">\n",
    "      </iframe>\n",
    "    '''.format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe seamless style=\"width:1200px;height:620px;border:0\" \n",
       "              srcdoc=\"\n",
       "      <script>\n",
       "        function load() {\n",
       "          document.getElementById('graph0.12296989562058469').pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 9\\n          }\\n        }\\n        tensor_content: &quot;<stripped 743040 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        tensor_content: &quot;<stripped 82560 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_1&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/mse_grad/Prod_1&quot;\\n  input: &quot;gradients/mse_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/mse_grad/Prod&quot;\\n  input: &quot;gradients/mse_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/mse_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_theta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_theta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n}\\n';\n",
       "        }\n",
       "      </script>\n",
       "      <link \n",
       "         rel=&quot;import&quot; \n",
       "         href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot;\n",
       "         onload=load() />\n",
       "      <div style=&quot;height:600px&quot;>\n",
       "        <tf-graph-basic id=&quot;graph0.12296989562058469&quot;><t/tf-graph-basic>\n",
       "      </div>\n",
       "    \">\n",
       "      </iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualizing with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "now = datetime.utcnow().strftime('%Y%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = 'X')\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1., seed = 42), \n",
    "                    name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = eta)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      " [[ 2.07001591]\n",
      " [ 0.82045609]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.31134021]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.87950081]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(\n",
    "                    feed_dict = { X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "            s.run(training_op, feed_dict = { X: X_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "summary_writer.flush()\n",
    "summary_writer.close()\n",
    "print('Best theta:\\n', best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x  3 dsatterthwaite  staff  102 May  2 08:55 \u001b[34mrun-201702155537\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  5 dsatterthwaite  staff  170 Apr 26 15:25 \u001b[34mrun-201726213820\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the command line run:\n",
    "\n",
    "`> source ~/tensorflow/bin/activate`\n",
    "\n",
    "`> tensorboard --logdir tf_logs/`\n",
    "\n",
    "Open in localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = 'X')\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1., 1., seed = 42), \n",
    "                    name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "\n",
    "# Wrap 'error' and 'mse' within the 'loss' name scope\n",
    "with tf.name_scope('loss') as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "    \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = eta)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      " [[ 2.06562495]\n",
      " [ 0.82996982]\n",
      " [ 0.11778412]\n",
      " [-0.27003285]\n",
      " [ 0.29147986]\n",
      " [-0.00638249]\n",
      " [-0.05427555]\n",
      " [-0.89488846]\n",
      " [-0.8678754 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(\n",
    "                    feed_dict = { X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "            s.run(training_op, feed_dict = { X: X_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "summary_writer.flush()\n",
    "summary_writer.close()\n",
    "print('Best theta:\\n', best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.name_scope('relu'):\n",
    "        W_shape = (int(X.get_shape()[1]), 1)\n",
    "        W = tf.Variable(tf.random_normal(W_shape), name = 'weights')\n",
    "        b = tf.Variable(0.0, name = 'bias')\n",
    "        z = tf.add(tf.matmul(X, W), b, name = 'z')\n",
    "        return tf.maximum(z, 0., name = 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = 'X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "# add_n() computes the sum of a list of tensors\n",
    "outputs = tf.add_n(relus, name = 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sharing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope('relu'):\n",
    "        W_shape = (int(X.get_shape()[1]), 1)\n",
    "        W = tf.Variable(tf.random_normal(W_shape), name = 'weights')\n",
    "        b = tf.Variable(0.0, name = 'bias')\n",
    "        linear = tf.add(tf.matmul(X, W), b, name = 'linear')\n",
    "        return tf.maximum(linear, threshold, name = 'max')\n",
    "    \n",
    "threshold = tf.Variable(0.0, name = 'threshold')\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = 'X')\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope('relu'):\n",
    "        if not hasattr(relu, 'threshold'):\n",
    "            relu.threshold = tf.Variable(0.0, name = 'threshold')\n",
    "        W_shape = (int(X.get_shape()[1]), 1)\n",
    "        W = tf.Variable(tf.random_normal(W_shape), name = 'weights')\n",
    "        b = tf.Variable(0.0, name = 'bias')\n",
    "        linear = tf.add(tf.matmul(X, W), b, name = 'linear')\n",
    "        return tf.maximum(linear, relu.threshold, name = 'max')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = 'X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope('relu', reuse = True):\n",
    "        threshold = tf.get_varibale(\n",
    "            'threshold', \n",
    "            shape = (), \n",
    "            initializer = tf.constant.initializer(0.0))\n",
    "        W_shape = (int(X.get_shape()[1]), 1)\n",
    "        W = tf.Variable(tf.random_normal(W_shape), name = 'weights')\n",
    "        b = tf.Variable(0.0, name = 'bias')\n",
    "        linear = tf.add(tf.matmul(X, W), b, name = 'linear')\n",
    "        return tf.maximum(linear, threshold, name = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope('relu'):\n",
    "        threshold = tf.get_variable(\n",
    "            'threshold', \n",
    "            shape = (), \n",
    "            initializer = tf.constant_initializer(0.0))\n",
    "        W_shape = int(X.get_shape()[1]), 1\n",
    "        W = tf.Variable(tf.random_normal(W_shape), name = 'weights')\n",
    "        b = tf.Variable(0.0, name = 'bias')\n",
    "        linear = tf.add(tf.matmul(X, W), b, name = 'linear')\n",
    "        return tf.maximum(linear, threshold, name = 'max')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = 'X')\n",
    "\n",
    "with tf.variable_scope('', default_name = '') as scope:\n",
    "    first_relu = relu(X)     # create the shared variable\n",
    "    scope.reuse_variables()  # then reuse it\n",
    "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
    "    \n",
    "output = tf.add_n(relus, name = 'output')\n",
    "\n",
    "#summary_writer = tf.summary.FileWriter(\n",
    "#    'logs/relu8', tf.get_default_graph())\n",
    "#summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
