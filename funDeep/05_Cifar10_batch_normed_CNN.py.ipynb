{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10_input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from tensorflow.python.ops import control_flow_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10_input.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "# Architecture\n",
    "N_HIDDEN_1 = 256\n",
    "N_HIDDEN_2 = 256\n",
    "ETA = 0.01\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 128\n",
    "DISPLAY_STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(eval_data=True):\n",
    "    data_dir = os.path.join('data/cifar10_data', 'cifar-10-batches-bin')\n",
    "    return cifar10_input.inputs(\n",
    "        eval_data=eval_data, data_dir=data_dir, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs():\n",
    "    data_dir = os.path.join('data/cifar10_data', 'cifar-10-batches-bin')\n",
    "    return cifar10_input.distorted_inputs(data_dir=data_dir, \n",
    "                                          batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, layer_type):\n",
    "    beta_init  = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    beta  = tf.get_variable('beta',  [n_out], initializer=beta_init)\n",
    "    gamma = tf.get_variable('gamma', [n_out], initializer=gamma_init)\n",
    "    axes = [0, 1, 2] if layer_type == 'conv' else [0]\n",
    "    batch_mean, batch_var = tf.nn.moments(x, axes, name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    \n",
    "    def  mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    \n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    mean, var = control_flow_ops.cond(\n",
    "        phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "    \n",
    "    if layer_type != 'conv':\n",
    "        x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(\n",
    "        x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    if layer_type != 'conv':\n",
    "        normed = tf.reshape(normed, [-1, n_out])\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_batch_norm(x, n_out, phase_train):    \n",
    "    return batch_norm(x, n_out, phase_train, 'conv')\n",
    "\n",
    "\n",
    "def layer_batch_norm(x, n_out, phase_train):\n",
    "    return batch_norm(x, n_out, phase_train, 'fully_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_summary(V, weight_shape):\n",
    "    ix = weight_shape[0] # ??? not used\n",
    "    iy = weight_shape[1] # ???\n",
    "    cx, cy = 8, 8        # ???\n",
    "    V_T = tf.transpose(V, (3, 0, 1, 2)) # magic numbers!\n",
    "    tf.summary.image('filters', V_T, max_outputs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input, weight_shape, bias_shape, phase_train, visualize=False):\n",
    "    incoming = weight_shape[0] * weight_shape[1] * weight_shape[2]\n",
    "    weight_init = tf.random_normal_initializer(\n",
    "        stddev=(2. / incoming) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable('W', weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable('b', bias_shape, initializer=bias_init)\n",
    "    logits = tf.nn.bias_add(\n",
    "        tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME'), \n",
    "        b)\n",
    "    if visualize: filter_summary(W, weight_shape)\n",
    "    return tf.nn.relu(conv_batch_norm(\n",
    "        logits, weight_shape[3], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(input, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape, phase_train):\n",
    "    weight_init = tf.random_normal_initializer(\n",
    "        stddev=(2. / weight_shape[0]) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable('W', weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable('b', bias_shape, initializer=bias_init)\n",
    "    logits = tf.matmul(input, W) + b\n",
    "    return tf.nn.relu(layer_batch_norm(\n",
    "        logits, weight_shape[1], phase_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(x, keep_prob, phase_train):\n",
    "    with tf.variable_scope('conv_1'):\n",
    "        conv_1 = conv2d(\n",
    "            x, [5, 5, 3, 64], [64], phase_train, visualize=True)\n",
    "        pool_1 = max_pool(conv_1)\n",
    "    with tf.variable_scope('conv_2'):\n",
    "        conv_2 = conv2d(pool_1, [5, 5, 64, 64], [64], phase_train)\n",
    "        pool_2 = max_pool(conv_2)\n",
    "    with tf.variable_scope('fc_1'): # fully connected\n",
    "        dim = 1\n",
    "        for d in pool_2.get_shape()[1:].as_list():\n",
    "            dim *= d\n",
    "        pool_2_flat = tf.reshape(pool_2, [-1, dim])\n",
    "        fc_1 = layer(pool_2_flat, [dim, 384], [384], phase_train)\n",
    "        \n",
    "        # Apply dropout\n",
    "        fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "    with tf.variable_scope('fc_2'):\n",
    "        fc_2 = layer(fc_1_drop, [384, 192], [192], phase_train)\n",
    "        \n",
    "        # Apply dropout\n",
    "        fc_2_drop = tf.nn.dropout(fc_2, keep_prob)\n",
    "    with tf.variable_scope('output'):\n",
    "        output = layer(fc_2_drop, [192, 10], [10], phase_train)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=output, labels=tf.cast(y, tf.int64))\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar('cost', cost)\n",
    "    optimizer = tf.train.AdamOptimizer(ETA)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_pred = tf.equal(tf.cast(tf.argmax(output, 1), dtype=tf.int32),\n",
    "                            y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar('validation_error', 1. - accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "Epoch: 0001\tCost: 1.660202\tValidation error: 0.460938\n",
      "Epoch: 0002\tCost: 1.313401\tValidation error: 0.367188\n",
      "Epoch: 0003\tCost: 1.174350\tValidation error: 0.343750\n",
      "Epoch: 0004\tCost: 1.085870\tValidation error: 0.234375\n",
      "Epoch: 0005\tCost: 1.029030\tValidation error: 0.265625\n",
      "Epoch: 0006\tCost: 0.998964\tValidation error: 0.242188\n",
      "Epoch: 0007\tCost: 0.957401\tValidation error: 0.179688\n",
      "Epoch: 0008\tCost: 0.934747\tValidation error: 0.265625\n",
      "Epoch: 0009\tCost: 0.910355\tValidation error: 0.164062\n",
      "Epoch: 0010\tCost: 0.897537\tValidation error: 0.257812\n",
      "Epoch: 0011\tCost: 0.870341\tValidation error: 0.187500\n",
      "Epoch: 0012\tCost: 0.851445\tValidation error: 0.179688\n",
      "Epoch: 0013\tCost: 0.847089\tValidation error: 0.218750\n",
      "Epoch: 0014\tCost: 0.815981\tValidation error: 0.179688\n",
      "Epoch: 0015\tCost: 0.815756\tValidation error: 0.210938\n",
      "Epoch: 0016\tCost: 0.801222\tValidation error: 0.203125\n",
      "Epoch: 0017\tCost: 0.794212\tValidation error: 0.203125\n",
      "Epoch: 0018\tCost: 0.783388\tValidation error: 0.226562\n",
      "Epoch: 0019\tCost: 0.776089\tValidation error: 0.164062\n",
      "Epoch: 0020\tCost: 0.764907\tValidation error: 0.234375\n",
      "Epoch: 0021\tCost: 0.755847\tValidation error: 0.195312\n",
      "Epoch: 0022\tCost: 0.744498\tValidation error: 0.187500\n",
      "Epoch: 0023\tCost: 0.742891\tValidation error: 0.210938\n",
      "Epoch: 0024\tCost: 0.738012\tValidation error: 0.125000\n",
      "Epoch: 0025\tCost: 0.723082\tValidation error: 0.187500\n",
      "Epoch: 0026\tCost: 0.716438\tValidation error: 0.117188\n",
      "Epoch: 0027\tCost: 0.712798\tValidation error: 0.234375\n",
      "Epoch: 0028\tCost: 0.708175\tValidation error: 0.242188\n",
      "Epoch: 0029\tCost: 0.698652\tValidation error: 0.179688\n",
      "Epoch: 0030\tCost: 0.698311\tValidation error: 0.195312\n",
      "Epoch: 0031\tCost: 0.691107\tValidation error: 0.164062\n",
      "Epoch: 0032\tCost: 0.674430\tValidation error: 0.234375\n",
      "Epoch: 0033\tCost: 0.688470\tValidation error: 0.171875\n",
      "Epoch: 0034\tCost: 0.675236\tValidation error: 0.156250\n",
      "Epoch: 0035\tCost: 0.678395\tValidation error: 0.148438\n",
      "Epoch: 0036\tCost: 0.664777\tValidation error: 0.164062\n",
      "Epoch: 0037\tCost: 0.667642\tValidation error: 0.140625\n",
      "Epoch: 0038\tCost: 0.663032\tValidation error: 0.179688\n",
      "Epoch: 0039\tCost: 0.650793\tValidation error: 0.140625\n",
      "Epoch: 0040\tCost: 0.648812\tValidation error: 0.203125\n",
      "Epoch: 0041\tCost: 0.643118\tValidation error: 0.210938\n",
      "Epoch: 0042\tCost: 0.638946\tValidation error: 0.179688\n",
      "Epoch: 0043\tCost: 0.642699\tValidation error: 0.179688\n",
      "Epoch: 0044\tCost: 0.634936\tValidation error: 0.187500\n",
      "Epoch: 0045\tCost: 0.628247\tValidation error: 0.187500\n",
      "Epoch: 0046\tCost: 0.631930\tValidation error: 0.148438\n",
      "Epoch: 0047\tCost: 0.623727\tValidation error: 0.187500\n",
      "Epoch: 0048\tCost: 0.619136\tValidation error: 0.195312\n",
      "Epoch: 0049\tCost: 0.621938\tValidation error: 0.140625\n",
      "Epoch: 0050\tCost: 0.617713\tValidation error: 0.203125\n",
      "Epoch: 0051\tCost: 0.616610\tValidation error: 0.187500\n",
      "Epoch: 0052\tCost: 0.608930\tValidation error: 0.179688\n",
      "Epoch: 0053\tCost: 0.600090\tValidation error: 0.203125\n",
      "Epoch: 0054\tCost: 0.610121\tValidation error: 0.148438\n",
      "Epoch: 0055\tCost: 0.602494\tValidation error: 0.109375\n",
      "Epoch: 0056\tCost: 0.603259\tValidation error: 0.195312\n",
      "Epoch: 0057\tCost: 0.595465\tValidation error: 0.156250\n",
      "Epoch: 0058\tCost: 0.594202\tValidation error: 0.171875\n",
      "Epoch: 0059\tCost: 0.593729\tValidation error: 0.179688\n",
      "Epoch: 0060\tCost: 0.587060\tValidation error: 0.179688\n",
      "Epoch: 0061\tCost: 0.583339\tValidation error: 0.195312\n",
      "Epoch: 0062\tCost: 0.583242\tValidation error: 0.203125\n",
      "Epoch: 0063\tCost: 0.582776\tValidation error: 0.242188\n",
      "Epoch: 0064\tCost: 0.584421\tValidation error: 0.117188\n",
      "Epoch: 0065\tCost: 0.578001\tValidation error: 0.203125\n",
      "Epoch: 0066\tCost: 0.572957\tValidation error: 0.218750\n",
      "Epoch: 0067\tCost: 0.576269\tValidation error: 0.125000\n",
      "Epoch: 0068\tCost: 0.573549\tValidation error: 0.195312\n",
      "Epoch: 0069\tCost: 0.575744\tValidation error: 0.171875\n",
      "Epoch: 0070\tCost: 0.583903\tValidation error: 0.171875\n",
      "Epoch: 0071\tCost: 0.565765\tValidation error: 0.195312\n",
      "Epoch: 0072\tCost: 0.564222\tValidation error: 0.140625\n",
      "Epoch: 0073\tCost: 0.562951\tValidation error: 0.187500\n",
      "Epoch: 0074\tCost: 0.561159\tValidation error: 0.156250\n",
      "Epoch: 0075\tCost: 0.559250\tValidation error: 0.148438\n",
      "Epoch: 0076\tCost: 0.567716\tValidation error: 0.148438\n",
      "Epoch: 0077\tCost: 0.555689\tValidation error: 0.164062\n",
      "Epoch: 0078\tCost: 0.560101\tValidation error: 0.148438\n",
      "Epoch: 0079\tCost: 0.558084\tValidation error: 0.187500\n",
      "Epoch: 0080\tCost: 0.554295\tValidation error: 0.132812\n",
      "Epoch: 0081\tCost: 0.551771\tValidation error: 0.179688\n",
      "Epoch: 0082\tCost: 0.550820\tValidation error: 0.218750\n",
      "Epoch: 0083\tCost: 0.538562\tValidation error: 0.164062\n",
      "Epoch: 0084\tCost: 0.542545\tValidation error: 0.156250\n",
      "Epoch: 0085\tCost: 0.543770\tValidation error: 0.171875\n",
      "Epoch: 0086\tCost: 0.549378\tValidation error: 0.156250\n",
      "Epoch: 0087\tCost: 0.540173\tValidation error: 0.179688\n",
      "Epoch: 0088\tCost: 0.536527\tValidation error: 0.125000\n",
      "Epoch: 0089\tCost: 0.537629\tValidation error: 0.187500\n",
      "Epoch: 0090\tCost: 0.544873\tValidation error: 0.148438\n",
      "Epoch: 0091\tCost: 0.536556\tValidation error: 0.156250\n",
      "Epoch: 0092\tCost: 0.529883\tValidation error: 0.164062\n",
      "Epoch: 0093\tCost: 0.530920\tValidation error: 0.226562\n",
      "Epoch: 0094\tCost: 0.531384\tValidation error: 0.125000\n",
      "Epoch: 0095\tCost: 0.525694\tValidation error: 0.164062\n",
      "Epoch: 0096\tCost: 0.531881\tValidation error: 0.179688\n",
      "Epoch: 0097\tCost: 0.529813\tValidation error: 0.156250\n",
      "Epoch: 0098\tCost: 0.527767\tValidation error: 0.171875\n",
      "Epoch: 0099\tCost: 0.527923\tValidation error: 0.195312\n",
      "Epoch: 0100\tCost: 0.524668\tValidation error: 0.164062\n",
      "Epoch: 0101\tCost: 0.522826\tValidation error: 0.179688\n",
      "Epoch: 0102\tCost: 0.521515\tValidation error: 0.125000\n",
      "Epoch: 0103\tCost: 0.518090\tValidation error: 0.156250\n",
      "Epoch: 0104\tCost: 0.519562\tValidation error: 0.148438\n",
      "Epoch: 0105\tCost: 0.514815\tValidation error: 0.109375\n",
      "Epoch: 0106\tCost: 0.514140\tValidation error: 0.179688\n",
      "Epoch: 0107\tCost: 0.514202\tValidation error: 0.148438\n",
      "Epoch: 0108\tCost: 0.521854\tValidation error: 0.132812\n",
      "Epoch: 0109\tCost: 0.512529\tValidation error: 0.195312\n",
      "Epoch: 0110\tCost: 0.518264\tValidation error: 0.156250\n",
      "Epoch: 0111\tCost: 0.512562\tValidation error: 0.117188\n",
      "Epoch: 0112\tCost: 0.518878\tValidation error: 0.148438\n",
      "Epoch: 0113\tCost: 0.507680\tValidation error: 0.140625\n",
      "Epoch: 0114\tCost: 0.511854\tValidation error: 0.132812\n",
      "Epoch: 0115\tCost: 0.505588\tValidation error: 0.140625\n",
      "Epoch: 0116\tCost: 0.508108\tValidation error: 0.164062\n",
      "Epoch: 0117\tCost: 0.504699\tValidation error: 0.156250\n",
      "Epoch: 0118\tCost: 0.500703\tValidation error: 0.140625\n",
      "Epoch: 0119\tCost: 0.502406\tValidation error: 0.140625\n",
      "Epoch: 0120\tCost: 0.500340\tValidation error: 0.140625\n",
      "Epoch: 0121\tCost: 0.517145\tValidation error: 0.164062\n",
      "Epoch: 0122\tCost: 0.495858\tValidation error: 0.148438\n",
      "Epoch: 0123\tCost: 0.508277\tValidation error: 0.179688\n",
      "Epoch: 0124\tCost: 0.493975\tValidation error: 0.156250\n",
      "Epoch: 0125\tCost: 0.496926\tValidation error: 0.179688\n",
      "Epoch: 0126\tCost: 0.496116\tValidation error: 0.187500\n",
      "Epoch: 0127\tCost: 0.494930\tValidation error: 0.117188\n",
      "Epoch: 0128\tCost: 0.497768\tValidation error: 0.140625\n",
      "Epoch: 0129\tCost: 0.490777\tValidation error: 0.156250\n",
      "Epoch: 0130\tCost: 0.495993\tValidation error: 0.210938\n",
      "Epoch: 0131\tCost: 0.494952\tValidation error: 0.164062\n",
      "Epoch: 0132\tCost: 0.488104\tValidation error: 0.117188\n",
      "Epoch: 0133\tCost: 0.488346\tValidation error: 0.187500\n",
      "Epoch: 0134\tCost: 0.483061\tValidation error: 0.140625\n",
      "Epoch: 0135\tCost: 0.490025\tValidation error: 0.109375\n",
      "Epoch: 0136\tCost: 0.490927\tValidation error: 0.109375\n",
      "Epoch: 0137\tCost: 0.485299\tValidation error: 0.117188\n",
      "Epoch: 0138\tCost: 0.489842\tValidation error: 0.156250\n",
      "Epoch: 0139\tCost: 0.485974\tValidation error: 0.148438\n",
      "Epoch: 0140\tCost: 0.482586\tValidation error: 0.132812\n",
      "Epoch: 0141\tCost: 0.480485\tValidation error: 0.171875\n",
      "Epoch: 0142\tCost: 0.486007\tValidation error: 0.187500\n",
      "Epoch: 0143\tCost: 0.484019\tValidation error: 0.132812\n",
      "Epoch: 0144\tCost: 0.482845\tValidation error: 0.125000\n",
      "Epoch: 0145\tCost: 0.484649\tValidation error: 0.101562\n",
      "Epoch: 0146\tCost: 0.476697\tValidation error: 0.171875\n",
      "Epoch: 0147\tCost: 0.478744\tValidation error: 0.156250\n",
      "Epoch: 0148\tCost: 0.474148\tValidation error: 0.164062\n",
      "Epoch: 0149\tCost: 0.479186\tValidation error: 0.109375\n",
      "Epoch: 0150\tCost: 0.479802\tValidation error: 0.210938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0151\tCost: 0.467442\tValidation error: 0.179688\n",
      "Epoch: 0152\tCost: 0.480242\tValidation error: 0.070312\n",
      "Epoch: 0153\tCost: 0.472149\tValidation error: 0.125000\n",
      "Epoch: 0154\tCost: 0.470930\tValidation error: 0.187500\n",
      "Epoch: 0155\tCost: 0.465767\tValidation error: 0.117188\n",
      "Epoch: 0156\tCost: 0.472933\tValidation error: 0.125000\n",
      "Epoch: 0157\tCost: 0.468192\tValidation error: 0.148438\n",
      "Epoch: 0158\tCost: 0.464804\tValidation error: 0.125000\n",
      "Epoch: 0159\tCost: 0.470045\tValidation error: 0.242188\n",
      "Epoch: 0160\tCost: 0.467862\tValidation error: 0.171875\n",
      "Epoch: 0161\tCost: 0.468586\tValidation error: 0.132812\n",
      "Epoch: 0162\tCost: 0.469608\tValidation error: 0.187500\n",
      "Epoch: 0163\tCost: 0.464095\tValidation error: 0.195312\n",
      "Epoch: 0164\tCost: 0.462428\tValidation error: 0.156250\n",
      "Epoch: 0165\tCost: 0.463708\tValidation error: 0.125000\n",
      "Epoch: 0166\tCost: 0.456648\tValidation error: 0.125000\n",
      "Epoch: 0167\tCost: 0.472357\tValidation error: 0.125000\n",
      "Epoch: 0168\tCost: 0.462747\tValidation error: 0.164062\n",
      "Epoch: 0169\tCost: 0.460080\tValidation error: 0.148438\n",
      "Epoch: 0170\tCost: 0.457001\tValidation error: 0.132812\n",
      "Epoch: 0171\tCost: 0.461510\tValidation error: 0.195312\n",
      "Epoch: 0172\tCost: 0.457962\tValidation error: 0.179688\n",
      "Epoch: 0173\tCost: 0.468231\tValidation error: 0.164062\n",
      "Epoch: 0174\tCost: 0.457541\tValidation error: 0.171875\n",
      "Epoch: 0175\tCost: 0.459991\tValidation error: 0.171875\n",
      "Epoch: 0176\tCost: 0.456943\tValidation error: 0.070312\n",
      "Epoch: 0177\tCost: 0.453296\tValidation error: 0.117188\n",
      "Epoch: 0178\tCost: 0.457788\tValidation error: 0.218750\n",
      "Epoch: 0179\tCost: 0.453074\tValidation error: 0.164062\n",
      "Epoch: 0180\tCost: 0.455514\tValidation error: 0.164062\n",
      "Epoch: 0181\tCost: 0.443780\tValidation error: 0.148438\n",
      "Epoch: 0182\tCost: 0.450907\tValidation error: 0.125000\n",
      "Epoch: 0183\tCost: 0.453476\tValidation error: 0.125000\n",
      "Epoch: 0184\tCost: 0.444939\tValidation error: 0.156250\n",
      "Epoch: 0185\tCost: 0.453929\tValidation error: 0.101562\n",
      "Epoch: 0186\tCost: 0.450888\tValidation error: 0.171875\n",
      "Epoch: 0187\tCost: 0.458456\tValidation error: 0.171875\n",
      "Epoch: 0188\tCost: 0.444555\tValidation error: 0.109375\n",
      "Epoch: 0189\tCost: 0.457415\tValidation error: 0.171875\n",
      "Epoch: 0190\tCost: 0.443919\tValidation error: 0.132812\n",
      "Epoch: 0191\tCost: 0.449946\tValidation error: 0.117188\n",
      "Epoch: 0192\tCost: 0.445566\tValidation error: 0.109375\n",
      "Epoch: 0193\tCost: 0.449757\tValidation error: 0.125000\n",
      "Epoch: 0194\tCost: 0.449589\tValidation error: 0.109375\n",
      "Epoch: 0195\tCost: 0.444528\tValidation error: 0.140625\n",
      "Epoch: 0196\tCost: 0.440715\tValidation error: 0.085938\n",
      "Epoch: 0197\tCost: 0.447591\tValidation error: 0.226562\n",
      "Epoch: 0198\tCost: 0.444491\tValidation error: 0.132812\n",
      "Epoch: 0199\tCost: 0.438412\tValidation error: 0.179688\n",
      "Epoch: 0200\tCost: 0.442438\tValidation error: 0.148438\n",
      "Epoch: 0201\tCost: 0.439302\tValidation error: 0.164062\n",
      "Epoch: 0202\tCost: 0.442772\tValidation error: 0.132812\n",
      "Epoch: 0203\tCost: 0.442463\tValidation error: 0.164062\n",
      "Epoch: 0204\tCost: 0.437591\tValidation error: 0.171875\n",
      "Epoch: 0205\tCost: 0.438507\tValidation error: 0.132812\n",
      "Epoch: 0206\tCost: 0.442756\tValidation error: 0.117188\n",
      "Epoch: 0207\tCost: 0.439869\tValidation error: 0.140625\n",
      "Epoch: 0208\tCost: 0.434996\tValidation error: 0.171875\n",
      "Epoch: 0209\tCost: 0.432385\tValidation error: 0.203125\n",
      "Epoch: 0210\tCost: 0.440670\tValidation error: 0.132812\n",
      "Epoch: 0211\tCost: 0.433185\tValidation error: 0.093750\n",
      "Epoch: 0212\tCost: 0.437176\tValidation error: 0.132812\n",
      "Epoch: 0213\tCost: 0.440551\tValidation error: 0.132812\n",
      "Epoch: 0214\tCost: 0.439798\tValidation error: 0.195312\n",
      "Epoch: 0215\tCost: 0.431314\tValidation error: 0.179688\n",
      "Epoch: 0216\tCost: 0.429717\tValidation error: 0.156250\n",
      "Epoch: 0217\tCost: 0.435604\tValidation error: 0.125000\n",
      "Epoch: 0218\tCost: 0.431688\tValidation error: 0.187500\n",
      "Epoch: 0219\tCost: 0.431245\tValidation error: 0.148438\n",
      "Epoch: 0220\tCost: 0.431631\tValidation error: 0.187500\n",
      "Epoch: 0221\tCost: 0.433676\tValidation error: 0.156250\n",
      "Epoch: 0222\tCost: 0.436789\tValidation error: 0.148438\n",
      "Epoch: 0223\tCost: 0.435119\tValidation error: 0.125000\n",
      "Epoch: 0224\tCost: 0.440144\tValidation error: 0.148438\n",
      "Epoch: 0225\tCost: 0.428708\tValidation error: 0.179688\n",
      "Epoch: 0226\tCost: 0.430833\tValidation error: 0.109375\n",
      "Epoch: 0227\tCost: 0.429075\tValidation error: 0.187500\n",
      "Epoch: 0228\tCost: 0.423430\tValidation error: 0.156250\n",
      "Epoch: 0229\tCost: 0.424589\tValidation error: 0.125000\n",
      "Epoch: 0230\tCost: 0.429852\tValidation error: 0.125000\n",
      "Epoch: 0231\tCost: 0.432157\tValidation error: 0.148438\n",
      "Epoch: 0232\tCost: 0.430939\tValidation error: 0.125000\n",
      "Epoch: 0233\tCost: 0.429328\tValidation error: 0.156250\n",
      "Epoch: 0234\tCost: 0.430210\tValidation error: 0.132812\n",
      "Epoch: 0235\tCost: 0.425690\tValidation error: 0.132812\n",
      "Epoch: 0236\tCost: 0.426557\tValidation error: 0.125000\n",
      "Epoch: 0237\tCost: 0.422375\tValidation error: 0.148438\n",
      "Epoch: 0238\tCost: 0.425772\tValidation error: 0.109375\n",
      "Epoch: 0239\tCost: 0.425359\tValidation error: 0.148438\n",
      "Epoch: 0240\tCost: 0.425982\tValidation error: 0.140625\n",
      "Epoch: 0241\tCost: 0.425436\tValidation error: 0.148438\n",
      "Epoch: 0242\tCost: 0.424229\tValidation error: 0.164062\n",
      "Epoch: 0243\tCost: 0.426400\tValidation error: 0.179688\n",
      "Epoch: 0244\tCost: 0.422981\tValidation error: 0.140625\n",
      "Epoch: 0245\tCost: 0.425608\tValidation error: 0.164062\n",
      "Epoch: 0246\tCost: 0.418143\tValidation error: 0.195312\n",
      "Epoch: 0247\tCost: 0.421650\tValidation error: 0.140625\n",
      "Epoch: 0248\tCost: 0.424594\tValidation error: 0.125000\n",
      "Epoch: 0249\tCost: 0.420456\tValidation error: 0.179688\n",
      "Epoch: 0250\tCost: 0.413592\tValidation error: 0.140625\n",
      "Epoch: 0251\tCost: 0.422764\tValidation error: 0.125000\n",
      "Epoch: 0252\tCost: 0.410383\tValidation error: 0.187500\n",
      "Epoch: 0253\tCost: 0.421807\tValidation error: 0.195312\n",
      "Epoch: 0254\tCost: 0.413543\tValidation error: 0.187500\n",
      "Epoch: 0255\tCost: 0.420842\tValidation error: 0.109375\n",
      "Epoch: 0256\tCost: 0.417335\tValidation error: 0.101562\n",
      "Epoch: 0257\tCost: 0.421829\tValidation error: 0.132812\n",
      "Epoch: 0258\tCost: 0.408695\tValidation error: 0.109375\n",
      "Epoch: 0259\tCost: 0.419199\tValidation error: 0.156250\n",
      "Epoch: 0260\tCost: 0.418213\tValidation error: 0.148438\n",
      "Epoch: 0261\tCost: 0.412642\tValidation error: 0.195312\n",
      "Epoch: 0262\tCost: 0.414042\tValidation error: 0.140625\n",
      "Epoch: 0263\tCost: 0.409640\tValidation error: 0.132812\n",
      "Epoch: 0264\tCost: 0.411777\tValidation error: 0.117188\n",
      "Epoch: 0265\tCost: 0.413073\tValidation error: 0.164062\n",
      "Epoch: 0266\tCost: 0.412551\tValidation error: 0.164062\n",
      "Epoch: 0267\tCost: 0.411051\tValidation error: 0.132812\n",
      "Epoch: 0268\tCost: 0.414456\tValidation error: 0.210938\n",
      "Epoch: 0269\tCost: 0.411538\tValidation error: 0.171875\n",
      "Epoch: 0270\tCost: 0.416135\tValidation error: 0.164062\n",
      "Epoch: 0271\tCost: 0.412235\tValidation error: 0.171875\n",
      "Epoch: 0272\tCost: 0.406491\tValidation error: 0.132812\n",
      "Epoch: 0273\tCost: 0.410731\tValidation error: 0.187500\n",
      "Epoch: 0274\tCost: 0.412232\tValidation error: 0.164062\n",
      "Epoch: 0275\tCost: 0.410370\tValidation error: 0.140625\n",
      "Epoch: 0276\tCost: 0.405450\tValidation error: 0.140625\n",
      "Epoch: 0277\tCost: 0.410230\tValidation error: 0.148438\n",
      "Epoch: 0278\tCost: 0.412705\tValidation error: 0.148438\n",
      "Epoch: 0279\tCost: 0.415537\tValidation error: 0.132812\n",
      "Epoch: 0280\tCost: 0.408335\tValidation error: 0.085938\n",
      "Epoch: 0281\tCost: 0.410829\tValidation error: 0.164062\n",
      "Epoch: 0282\tCost: 0.405218\tValidation error: 0.117188\n",
      "Epoch: 0283\tCost: 0.410547\tValidation error: 0.210938\n",
      "Epoch: 0284\tCost: 0.401653\tValidation error: 0.125000\n",
      "Epoch: 0285\tCost: 0.405715\tValidation error: 0.070312\n",
      "Epoch: 0286\tCost: 0.406523\tValidation error: 0.140625\n",
      "Epoch: 0287\tCost: 0.407530\tValidation error: 0.117188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-80d3ece7eca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                                    \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                    \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                    phase_train: True})\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;31m# Compute avg loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.variable_scope('cifar_conv_batchnorm_model'):\n",
    "            x = tf.placeholder('float', [None, 24, 24, 3])\n",
    "            y = tf.placeholder('int32', [None])\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            phase_train = tf.placeholder(tf.bool) # T=train, F=Valid/Test\n",
    "            distorted_images, distorted_labels = distorted_inputs()\n",
    "            val_images, val_labels = inputs()\n",
    "            output = inference(x, keep_prob, phase_train)\n",
    "            cost = loss(output, y)\n",
    "            global_step = tf.Variable(\n",
    "                0, name='global_step', trainable=False)\n",
    "            train_op = training(cost, global_step)\n",
    "            eval_op = evaluate(output, y)\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            sess = tf.Session()\n",
    "            summary_writer = tf.summary.FileWriter(\n",
    "                'conv_cifar_batchnorm_logs', graph=sess.graph)\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "            tf.train.start_queue_runners(sess=sess)\n",
    "            \n",
    "            # Train\n",
    "            for epoch in range(EPOCHS):\n",
    "                avg_cost = 0.\n",
    "                total_batches = int(\n",
    "                    cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / \n",
    "                    BATCH_SIZE)\n",
    "                \n",
    "                # Loop over batches\n",
    "                for i in range(total_batches):\n",
    "                    # Fit to batch\n",
    "                    train_x, train_y = sess.run([distorted_images, \n",
    "                                                 distorted_labels])\n",
    "                    _, new_cost = sess.run(\n",
    "                        [train_op, cost], \n",
    "                        feed_dict={x: train_x, \n",
    "                                   y: train_y, \n",
    "                                   keep_prob: 0.5, \n",
    "                                   phase_train: True})\n",
    "                    \n",
    "                    # Compute avg loss\n",
    "                    avg_cost += new_cost / total_batches\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % DISPLAY_STEP == 0:\n",
    "                    val_x, val_y = sess.run([val_images, val_labels])\n",
    "                    accuracy = sess.run(\n",
    "                        eval_op, \n",
    "                        feed_dict={x: val_x, \n",
    "                                   y: val_y, \n",
    "                                   keep_prob: 1., \n",
    "                                   phase_train: False})\n",
    "                    print('Epoch: %04d\\tCost: %.6f\\tValidation error: %.6f'\n",
    "                          %(epoch + 1, avg_cost, 1 - accuracy))\n",
    "                    summary_str = sess.run(\n",
    "                        summary_op, \n",
    "                        feed_dict={x: train_x, \n",
    "                                   y: train_y, \n",
    "                                   keep_prob: 1., \n",
    "                                   phase_train: False})\n",
    "                    summary_writer.add_summary(summary_str, \n",
    "                                               sess.run(global_step))\n",
    "                    saver.save(\n",
    "                        sess, \n",
    "                        'conv_cifar_batchnorm_logs/model-checkpoint', \n",
    "                        global_step=global_step)\n",
    "            print('Optimization finished!')\n",
    "            \n",
    "            val_x, val_y = sess.run([val_images, val_labels])\n",
    "            accuracy = sess.run(\n",
    "                eval_op, \n",
    "                feed_dict={x: val_x, \n",
    "                           y: val_y, \n",
    "                           keep_prob: 1., \n",
    "                           phase_train: False})\n",
    "            print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
