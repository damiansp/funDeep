{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cifar10_input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_input.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "# Architecture\n",
    "N_HIDDEN_1 = 256\n",
    "N_HIDDEN_2 = 256\n",
    "ETA = 0.001\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 128\n",
    "DISPLAY_STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(eval_data=True):\n",
    "    data_dir = os.path.join('data/cifar10_data', 'cifar-10-batches-bin')\n",
    "    return cifar10_input.inputs(\n",
    "        eval_data=eval_data, data_dir=data_dir, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs():\n",
    "    data_dir = os.path.join('data/cifar10_data', 'cifar-10-batches-bin')\n",
    "    return cifar10_input.distorted_inputs(data_dir=data_dir, \n",
    "                                          batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_summary(V, weight_shape):\n",
    "    ix = weight_shape[0] # ??? not used\n",
    "    iy = weight_shape[1] # ???\n",
    "    cx, cy = 8, 8        # ???\n",
    "    V_T = tf.transpose(V, (3, 0, 1, 2)) # magic numbers!\n",
    "    tf.summary.image('filters', V_T, max_outputs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input, weight_shape, bias_shape, visualize=False):\n",
    "    incoming = weight_shape[0] * weight_shape[1] * weight_shape[2]\n",
    "    weight_init = tf.random_normal_initializer(\n",
    "        stddev=(2. / incoming) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable('W', weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable('b', bias_shape, initializer=bias_init)\n",
    "    if visualize: filter_summary(W, weight_shape)\n",
    "    return tf.nn.relu(tf.nn.bias_add(\n",
    "        tf.nn.conv2d(\n",
    "            input, W, strides=[1, 1, 1, 1], padding='SAME'), \n",
    "        b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(input, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape):\n",
    "    weight_init = tf.random_normal_initializer(\n",
    "        stddev=(2. / weight_shape[0]) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable('W', weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable('b', bias_shape, initializer=bias_init)\n",
    "    return tf.nn.relu(tf.matmul(input, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(x, keep_prob):\n",
    "    with tf.variable_scope('conv_1'):\n",
    "        conv_1 = conv2d(x, [5, 5, 3, 64], [64], visualize=True)\n",
    "        pool_1 = max_pool(conv_1)\n",
    "    with tf.variable_scope('conv_2'):\n",
    "        conv_2 = conv2d(pool_1, [5, 5, 64, 64], [64])\n",
    "        pool_2 = max_pool(conv_2)\n",
    "    with tf.variable_scope('fc_1'): # fully connected\n",
    "        dim = 1\n",
    "        for d in pool_2.get_shape()[1:].as_list():\n",
    "            dim *= d\n",
    "        pool_2_flat = tf.reshape(pool_2, [-1, dim])\n",
    "        fc_1 = layer(pool_2_flat, [dim, 384], [384])\n",
    "        \n",
    "        # Apply dropout\n",
    "        fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "    with tf.variable_scope('fc_2'):\n",
    "        fc_2 = layer(fc_1_drop, [384, 192], [192])\n",
    "        \n",
    "        # Apply dropout\n",
    "        fc_2_drop = tf.nn.dropout(fc_2, keep_prob)\n",
    "    with tf.variable_scope('output'):\n",
    "        output = layer(fc_2_drop, [192, 10], [10])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=output, labels=tf.cast(y, tf.int64))\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar('cost', cost)\n",
    "    optimizer = tf.train.AdamOptimizer(ETA)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_pred = tf.equal(tf.cast(tf.argmax(output, 1), dtype=tf.int32),\n",
    "                            y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar('validation_error', 1. - accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "Epoch: 0001\tCost: 2.027943\tValidation error: 0.539062\n",
      "Epoch: 0002\tCost: 1.673000\tValidation error: 0.554688\n",
      "Epoch: 0003\tCost: 1.528226\tValidation error: 0.406250\n",
      "Epoch: 0004\tCost: 1.419284\tValidation error: 0.398438\n",
      "Epoch: 0005\tCost: 1.351768\tValidation error: 0.476562\n",
      "Epoch: 0006\tCost: 1.319155\tValidation error: 0.335938\n",
      "Epoch: 0007\tCost: 1.264800\tValidation error: 0.367188\n",
      "Epoch: 0008\tCost: 1.232235\tValidation error: 0.343750\n",
      "Epoch: 0009\tCost: 1.207253\tValidation error: 0.320312\n",
      "Epoch: 0010\tCost: 1.173475\tValidation error: 0.367188\n",
      "Epoch: 0011\tCost: 1.157171\tValidation error: 0.398438\n",
      "Epoch: 0012\tCost: 1.137940\tValidation error: 0.273438\n",
      "Epoch: 0013\tCost: 1.122789\tValidation error: 0.359375\n",
      "Epoch: 0014\tCost: 1.099199\tValidation error: 0.273438\n",
      "Epoch: 0015\tCost: 1.081709\tValidation error: 0.273438\n",
      "Epoch: 0016\tCost: 1.071992\tValidation error: 0.273438\n",
      "Epoch: 0017\tCost: 1.050765\tValidation error: 0.351562\n",
      "Epoch: 0018\tCost: 1.041755\tValidation error: 0.328125\n",
      "Epoch: 0019\tCost: 1.034229\tValidation error: 0.257812\n",
      "Epoch: 0020\tCost: 1.021285\tValidation error: 0.289062\n",
      "Epoch: 0021\tCost: 1.003371\tValidation error: 0.289062\n",
      "Epoch: 0022\tCost: 1.000794\tValidation error: 0.289062\n",
      "Epoch: 0023\tCost: 0.982660\tValidation error: 0.273438\n",
      "Epoch: 0024\tCost: 0.971983\tValidation error: 0.265625\n",
      "Epoch: 0025\tCost: 0.973204\tValidation error: 0.289062\n",
      "Epoch: 0026\tCost: 0.963339\tValidation error: 0.242188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4822a389845c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                     _, new_cost = sess.run(\n\u001b[1;32m     37\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         feed_dict={x: train_x, y: train_y, keep_prob: 0.5})\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0;31m# Compute avg loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.variable_scope('cifar_conv_model'):\n",
    "            x = tf.placeholder('float', [None, 24, 24, 3])\n",
    "            y = tf.placeholder('int32', [None])\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            distorted_images, distorted_labels = distorted_inputs()\n",
    "            val_images, val_labels = inputs()\n",
    "            output = inference(x, keep_prob)\n",
    "            cost = loss(output, y)\n",
    "            global_step = tf.Variable(\n",
    "                0, name='global_step', trainable=False)\n",
    "            train_op = training(cost, global_step)\n",
    "            eval_op = evaluate(output, y)\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            saver = tf.train.Saver()\n",
    "            sess = tf.Session()\n",
    "            summary_writer = tf.summary.FileWriter(\n",
    "                'conv_cifar_logs', graph=sess.graph)\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "            tf.train.start_queue_runners(sess=sess)\n",
    "            \n",
    "            # Train\n",
    "            for epoch in range(EPOCHS):\n",
    "                avg_cost = 0.\n",
    "                total_batches = int(\n",
    "                    cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / \n",
    "                    BATCH_SIZE)\n",
    "                \n",
    "                # Loop over batches\n",
    "                for i in range(total_batches):\n",
    "                    # Fit to batch\n",
    "                    train_x, train_y = sess.run([distorted_images, \n",
    "                                                 distorted_labels])\n",
    "                    _, new_cost = sess.run(\n",
    "                        [train_op, cost], \n",
    "                        feed_dict={x: train_x, y: train_y, keep_prob: 0.5})\n",
    "                    \n",
    "                    # Compute avg loss\n",
    "                    avg_cost += new_cost / total_batches\n",
    "                    \n",
    "                # Display logs per epoch step\n",
    "                if epoch % DISPLAY_STEP == 0:\n",
    "                    val_x, val_y = sess.run([val_images, val_labels])\n",
    "                    accuracy = sess.run(\n",
    "                        eval_op, \n",
    "                        feed_dict={x: val_x, y: val_y, keep_prob: 1.})\n",
    "                    print('Epoch: %04d\\tCost: %.6f\\tValidation error: %.6f'\n",
    "                          %(epoch + 1, avg_cost, 1 - accuracy))\n",
    "                    summary_str = sess.run(\n",
    "                        summary_op, \n",
    "                        feed_dict={x: train_x, y: train_y, keep_prob: 1.})\n",
    "                    summary_writer.add_summary(summary_str, \n",
    "                                               sess.run(global_step))\n",
    "                    saver.save(sess, \n",
    "                               'conv_cifar_logs/model-checkpoint', \n",
    "                               global_step=global_step)\n",
    "            print('Optimization finished!')\n",
    "            \n",
    "            val_x, val_y = sess.run([val_images, val_labels])\n",
    "            accuracy = sess.run(\n",
    "                eval_op, feed_dict={x: val_x, y: val_y, keep_prob: 1.})\n",
    "            print('Test Accuracy:', accuracy)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
